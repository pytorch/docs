


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta name="robots" content="noindex">
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>torch.distributed.pipelining.schedules &mdash; PyTorch main documentation</title>
  

  
  
  
  
    <link rel="canonical" href="https://pytorch.org/docs/stable/_modules/torch/distributed/pipelining/schedules.html"/>
  

  

  
  
    

  

  <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/copybutton.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/katex-math.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/sphinx-dropdown.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/panels-bootstrap.min.css" type="text/css" />
  <link rel="stylesheet" href="../../../../_static/css/jit.css" type="text/css" />
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />

<!--
  Search engines should not index the main version of documentation.
  Stable documentation are built without release == 'main'.
-->
<meta name="robots" content="noindex">


  <!-- Google Tag Manager -->
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-T8XT4PS');</script>
    <!-- End Google Tag Manager -->
  


  
  <script src="../../../../_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../../../../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../../../../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>

          <li class="main-menu-item">
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Learn
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/get-started">
                  <span class=dropdown-title>Get Started</span>
                  <p>Run PyTorch locally or get started quickly with one of the supported cloud platforms</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials">
                  <span class="dropdown-title">Tutorials</span>
                  <p>Whats new in PyTorch tutorials</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/basics/intro.html">
                  <span class="dropdown-title">Learn the Basics</span>
                  <p>Familiarize yourself with PyTorch concepts and modules</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/recipes/recipes_index.html">
                  <span class="dropdown-title">PyTorch Recipes</span>
                  <p>Bite-size, ready-to-deploy PyTorch code examples</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/introyt.html">
                  <span class="dropdown-title">Intro to PyTorch - YouTube Series</span>
                  <p>Master PyTorch basics with our engaging YouTube tutorial series</p>
                </a>
              </div>
            </div>
          </li>

          <li>
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Ecosystem
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/ecosystem">
                  <span class="dropdown-title">Tools</span>
                  <p>Learn about the tools and frameworks in the PyTorch Ecosystem</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/#community-module">
                  <span class=dropdown-title>Community</span>
                  <p>Join the PyTorch developer community to contribute, learn, and get your questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://discuss.pytorch.org/" target="_blank">
                  <span class=dropdown-title>Forums</span>
                  <p>A place to discuss PyTorch code, issues, install, research</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/resources">
                  <span class=dropdown-title>Developer Resources</span>
                  <p>Find resources and get questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/ecosystem/contributor-awards-2023">
                  <span class="dropdown-title">Contributor Awards - 2023</span>
                  <p>Award winners announced at this year's PyTorch Conference</p>
                </a>
              </div>
            </div>
          </li>

          <li>
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Edge
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/edge">
                  <span class="dropdown-title">About PyTorch Edge</span>
                  <p>Build innovative and privacy-aware AI experiences for edge devices</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/executorch-overview">
                  <span class="dropdown-title">ExecuTorch</span>
                  <p>End-to-end solution for enabling on-device inference capabilities across mobile and edge devices</p>
                </a>
              </div>
            </div>  
          </li>

          <li class="main-menu-item">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Docs
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/docs/stable/index.html">
                  <span class="dropdown-title">PyTorch</span>
                  <p>Explore the documentation for comprehensive guidance on how to use PyTorch</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/pytorch-domains">
                  <span class="dropdown-title">PyTorch Domains</span>
                  <p>Read the PyTorch Domains documentation to learn more about domain-specific libraries</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Blogs & News 
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/blog/">
                  <span class="dropdown-title">PyTorch Blog</span>
                  <p>Catch up on the latest technical news and happenings</p>
                </a>
                 <a class="nav-dropdown-item" href="https://pytorch.org/community-blog">
                  <span class="dropdown-title">Community Blog</span>
                  <p>Stories from the PyTorch ecosystem</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/videos">
                  <span class="dropdown-title">Videos</span>
                  <p>Learn about the latest PyTorch tutorials, new, and more </p>
                <a class="nav-dropdown-item" href="https://pytorch.org/community-stories">
                  <span class="dropdown-title">Community Stories</span>
                  <p>Learn how our community solves real, everyday machine learning problems with PyTorch</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/events">
                  <span class="dropdown-title">Events</span>
                  <p>Find events, webinars, and podcasts</p>
                </a>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                About
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/foundation">
                  <span class="dropdown-title">PyTorch Foundation</span>
                  <p>Learn more about the PyTorch Foundation</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/governing-board">
                  <span class="dropdown-title">Governing Board</span>
                  <p></p>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
            <div class="no-dropdown">
              <a href="https://pytorch.org/join" data-cta="join">
                Become a Member
              </a>
            </div>
          </li>
          <li>
           <div class="main-menu-item">
             <a href="https://github.com/pytorch/pytorch" class="github-icon">
             </a>
           </div>
          </li>
          <!--- TODO: This block adds the search icon to the nav bar. We will enable it later. 
          <li>
            <div class="main-menu-item">
             <a href="https://github.com/pytorch/pytorch" class="search-icon">
             </a>
            </div>
          </li>
          --->
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            
    <div class="version">
      <a href='https://pytorch.org/docs/versions.html'>main (2.5.0a0+gitdcdb254 ) &#x25BC</a>
    </div>
    


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          </div>

          

<div>
  <a style="color:#F05732" href="https://pytorch.org/docs/stable/_modules/torch/distributed/pipelining/schedules.html">
    You are viewing unstable developer preview docs.
    Click here to view docs for latest stable release.
  </a>
</div>


            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">Community</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../community/build_ci_governance.html">PyTorch Governance | Build + CI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../community/contribution_guide.html">PyTorch Contribution Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../community/design.html">PyTorch Design Philosophy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../community/governance.html">PyTorch Governance | Mechanics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../community/persons_of_interest.html">PyTorch Governance | Maintainers</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Developer Notes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/amp_examples.html">Automatic Mixed Precision examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/autograd.html">Autograd mechanics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/broadcasting.html">Broadcasting semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/cpu_threading_torchscript_inference.html">CPU threading and TorchScript inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/cuda.html">CUDA semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/custom_operators.html">PyTorch Custom Operators Landing Page</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/ddp.html">Distributed Data Parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/extending.html">Extending PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/extending.func.html">Extending torch.func with autograd.Function</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/faq.html">Frequently Asked Questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/fsdp.html">FSDP Notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/get_start_xpu.html">Pytorch 2.4: Getting Started on Intel GPU</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/gradcheck.html">Gradcheck mechanics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/hip.html">HIP (ROCm) semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/large_scale_deployments.html">Features for large-scale deployments</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/modules.html">Modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/mps.html">MPS backend</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/multiprocessing.html">Multiprocessing best practices</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/numerical_accuracy.html">Numerical accuracy</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/randomness.html">Reproducibility</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/serialization.html">Serialization semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notes/windows.html">Windows FAQ</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Language Bindings</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../cpp_index.html">C++</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/javadoc/">Javadoc</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../deploy.html">torch::deploy</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Python API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../torch.html">torch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../nn.html">torch.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../nn.functional.html">torch.nn.functional</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tensors.html">torch.Tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tensor_attributes.html">Tensor Attributes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tensor_view.html">Tensor Views</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../amp.html">torch.amp</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../autograd.html">torch.autograd</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../library.html">torch.library</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../cpu.html">torch.cpu</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../cuda.html">torch.cuda</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../torch_cuda_memory.html">Understanding CUDA Memory Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../torch_cuda_memory.html#generating-a-snapshot">Generating a Snapshot</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../torch_cuda_memory.html#using-the-visualizer">Using the visualizer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../torch_cuda_memory.html#snapshot-api-reference">Snapshot API Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../mps.html">torch.mps</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../xpu.html">torch.xpu</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../mtia.html">torch.mtia</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../meta.html">Meta device</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../backends.html">torch.backends</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../export.html">torch.export</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../distributed.html">torch.distributed</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../distributed.algorithms.join.html">torch.distributed.algorithms.join</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../distributed.elastic.html">torch.distributed.elastic</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../fsdp.html">torch.distributed.fsdp</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../distributed.optim.html">torch.distributed.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../distributed.pipelining.html">torch.distributed.pipelining</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../distributed.tensor.parallel.html">torch.distributed.tensor.parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../distributed.checkpoint.html">torch.distributed.checkpoint</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../distributions.html">torch.distributions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../torch.compiler.html">torch.compiler</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../fft.html">torch.fft</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../func.html">torch.func</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../futures.html">torch.futures</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../fx.html">torch.fx</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../fx.experimental.html">torch.fx.experimental</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../hub.html">torch.hub</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../jit.html">torch.jit</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../linalg.html">torch.linalg</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../monitor.html">torch.monitor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../signal.html">torch.signal</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../special.html">torch.special</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../torch.overrides.html">torch.overrides</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../package.html">torch.package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../profiler.html">torch.profiler</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../nn.init.html">torch.nn.init</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../nn.attention.html">torch.nn.attention</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../onnx.html">torch.onnx</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../optim.html">torch.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../complex_numbers.html">Complex Numbers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../ddp_comm_hooks.html">DDP Communication Hooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../quantization.html">Quantization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../rpc.html">Distributed RPC Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../random.html">torch.random</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../masked.html">torch.masked</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../nested.html">torch.nested</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../size.html">torch.Size</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../sparse.html">torch.sparse</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../storage.html">torch.Storage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../testing.html">torch.testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../utils.html">torch.utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../benchmark_utils.html">torch.utils.benchmark</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../bottleneck.html">torch.utils.bottleneck</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../checkpoint.html">torch.utils.checkpoint</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../cpp_extension.html">torch.utils.cpp_extension</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../data.html">torch.utils.data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../deterministic.html">torch.utils.deterministic</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../jit_utils.html">torch.utils.jit</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../dlpack.html">torch.utils.dlpack</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../mobile_optimizer.html">torch.utils.mobile_optimizer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../model_zoo.html">torch.utils.model_zoo</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../tensorboard.html">torch.utils.tensorboard</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../module_tracker.html">torch.utils.module_tracker</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../type_info.html">Type Info</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../named_tensor.html">Named Tensors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../name_inference.html">Named Tensors operator coverage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../config_mod.html">torch.__config__</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../future_mod.html">torch.__future__</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../logging.html">torch._logging</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../torch_environment_variables.html">Torch Environment Variables</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Libraries</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/audio/stable">torchaudio</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/data">TorchData</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/torchrec">TorchRec</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/serve">TorchServe</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/text/stable">torchtext</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/vision/stable">torchvision</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/xla/">PyTorch on XLA Devices</a></li>
</ul>

            
          

        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../../../../index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
          <li><a href="../../../index.html">Module code</a> &gt;</li>
        
          <li><a href="../../../torch.html">torch</a> &gt;</li>
        
          <li><a href="../../distributed.html">torch.distributed</a> &gt;</li>
        
      <li>torch.distributed.pipelining.schedules</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        

          <!-- Google Tag Manager (noscript) -->
          <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-T8XT4PS"
          height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
          <!-- End Google Tag Manager (noscript) -->
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <h1>Source code for torch.distributed.pipelining.schedules</h1><div class="highlight"><pre>
<span></span><span class="c1"># mypy: allow-untyped-defs</span>
<span class="c1"># Copyright (c) Meta Platforms, Inc. and affiliates</span>

<span class="kn">import</span> <span class="nn">csv</span>
<span class="kn">import</span> <span class="nn">itertools</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">from</span> <span class="nn">abc</span> <span class="kn">import</span> <span class="n">ABC</span><span class="p">,</span> <span class="n">abstractmethod</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">defaultdict</span>
<span class="kn">from</span> <span class="nn">enum</span> <span class="kn">import</span> <span class="n">Enum</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">NamedTuple</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Set</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.distributed</span> <span class="k">as</span> <span class="nn">dist</span>
<span class="kn">from</span> <span class="nn">torch.profiler</span> <span class="kn">import</span> <span class="n">record_function</span>

<span class="kn">from</span> <span class="nn">.microbatch</span> <span class="kn">import</span> <span class="n">merge_chunks</span><span class="p">,</span> <span class="n">split_args_kwargs_into_chunks</span><span class="p">,</span> <span class="n">TensorChunkSpec</span>
<span class="kn">from</span> <span class="nn">.stage</span> <span class="kn">import</span> <span class="n">_PipelineStageBase</span>


<span class="n">__all__</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;get_schedule_class&quot;</span><span class="p">,</span>
    <span class="s2">&quot;PipelineScheduleSingle&quot;</span><span class="p">,</span>
    <span class="s2">&quot;PipelineScheduleMulti&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Schedule1F1B&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ScheduleFlexibleInterleaved1F1B&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ScheduleGPipe&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ScheduleInterleaved1F1B&quot;</span><span class="p">,</span>
    <span class="s2">&quot;ScheduleLoopedBFS&quot;</span><span class="p">,</span>
<span class="p">]</span>

<span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">_ComputationType</span><span class="p">(</span><span class="n">Enum</span><span class="p">):</span>
    <span class="c1"># TODO(whc) rename to _ActType?</span>
    <span class="n">FORWARD</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">BACKWARD</span> <span class="o">=</span> <span class="mi">2</span>
    <span class="n">WEIGHT</span> <span class="o">=</span> <span class="mi">3</span>
    <span class="n">UNSHARD</span> <span class="o">=</span> <span class="mi">4</span>
    <span class="n">RESHARD</span> <span class="o">=</span> <span class="mi">5</span>
    <span class="n">SEND_F</span> <span class="o">=</span> <span class="mi">6</span>
    <span class="n">RECV_F</span> <span class="o">=</span> <span class="mi">7</span>
    <span class="n">SEND_B</span> <span class="o">=</span> <span class="mi">8</span>
    <span class="n">RECV_B</span> <span class="o">=</span> <span class="mi">9</span>

    <span class="k">def</span> <span class="fm">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">str_map</span> <span class="o">=</span> <span class="p">{</span>
            <span class="n">_ComputationType</span><span class="o">.</span><span class="n">FORWARD</span><span class="p">:</span> <span class="s2">&quot;F&quot;</span><span class="p">,</span>
            <span class="n">_ComputationType</span><span class="o">.</span><span class="n">BACKWARD</span><span class="p">:</span> <span class="s2">&quot;B&quot;</span><span class="p">,</span>
            <span class="n">_ComputationType</span><span class="o">.</span><span class="n">WEIGHT</span><span class="p">:</span> <span class="s2">&quot;W&quot;</span><span class="p">,</span>
            <span class="n">_ComputationType</span><span class="o">.</span><span class="n">UNSHARD</span><span class="p">:</span> <span class="s2">&quot;UNSHARD&quot;</span><span class="p">,</span>
            <span class="n">_ComputationType</span><span class="o">.</span><span class="n">RESHARD</span><span class="p">:</span> <span class="s2">&quot;RESHARD&quot;</span><span class="p">,</span>
            <span class="n">_ComputationType</span><span class="o">.</span><span class="n">SEND_F</span><span class="p">:</span> <span class="s2">&quot;SEND_F&quot;</span><span class="p">,</span>
            <span class="n">_ComputationType</span><span class="o">.</span><span class="n">RECV_F</span><span class="p">:</span> <span class="s2">&quot;RECV_F&quot;</span><span class="p">,</span>
            <span class="n">_ComputationType</span><span class="o">.</span><span class="n">SEND_B</span><span class="p">:</span> <span class="s2">&quot;SEND_B&quot;</span><span class="p">,</span>
            <span class="n">_ComputationType</span><span class="o">.</span><span class="n">RECV_B</span><span class="p">:</span> <span class="s2">&quot;RECV_B&quot;</span><span class="p">,</span>
        <span class="p">}</span>
        <span class="k">return</span> <span class="n">str_map</span><span class="p">[</span><span class="bp">self</span><span class="p">]</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">from_str</span><span class="p">(</span><span class="n">action</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">action</span> <span class="o">==</span> <span class="s2">&quot;F&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">_ComputationType</span><span class="o">.</span><span class="n">FORWARD</span>
        <span class="k">elif</span> <span class="n">action</span> <span class="o">==</span> <span class="s2">&quot;B&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">_ComputationType</span><span class="o">.</span><span class="n">BACKWARD</span>
        <span class="k">elif</span> <span class="n">action</span> <span class="o">==</span> <span class="s2">&quot;W&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">_ComputationType</span><span class="o">.</span><span class="n">WEIGHT</span>
        <span class="k">elif</span> <span class="n">action</span> <span class="o">==</span> <span class="s2">&quot;UNSHARD&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">_ComputationType</span><span class="o">.</span><span class="n">UNSHARD</span>
        <span class="k">elif</span> <span class="n">action</span> <span class="o">==</span> <span class="s2">&quot;RESHARD&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">_ComputationType</span><span class="o">.</span><span class="n">RESHARD</span>
        <span class="k">elif</span> <span class="n">action</span> <span class="o">==</span> <span class="s2">&quot;SEND_F&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">_ComputationType</span><span class="o">.</span><span class="n">SEND_F</span>
        <span class="k">elif</span> <span class="n">action</span> <span class="o">==</span> <span class="s2">&quot;RECV_F&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">_ComputationType</span><span class="o">.</span><span class="n">RECV_F</span>
        <span class="k">elif</span> <span class="n">action</span> <span class="o">==</span> <span class="s2">&quot;SEND_B&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">_ComputationType</span><span class="o">.</span><span class="n">SEND_B</span>
        <span class="k">elif</span> <span class="n">action</span> <span class="o">==</span> <span class="s2">&quot;RECV_B&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">_ComputationType</span><span class="o">.</span><span class="n">RECV_B</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Invalid computation type </span><span class="si">{</span><span class="n">action</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>


<span class="n">FORWARD</span> <span class="o">=</span> <span class="n">_ComputationType</span><span class="o">.</span><span class="n">FORWARD</span>
<span class="n">BACKWARD</span> <span class="o">=</span> <span class="n">_ComputationType</span><span class="o">.</span><span class="n">BACKWARD</span>
<span class="n">WEIGHT</span> <span class="o">=</span> <span class="n">_ComputationType</span><span class="o">.</span><span class="n">WEIGHT</span>
<span class="n">UNSHARD</span> <span class="o">=</span> <span class="n">_ComputationType</span><span class="o">.</span><span class="n">UNSHARD</span>
<span class="n">RESHARD</span> <span class="o">=</span> <span class="n">_ComputationType</span><span class="o">.</span><span class="n">RESHARD</span>
<span class="n">SEND_F</span> <span class="o">=</span> <span class="n">_ComputationType</span><span class="o">.</span><span class="n">SEND_F</span>
<span class="n">RECV_F</span> <span class="o">=</span> <span class="n">_ComputationType</span><span class="o">.</span><span class="n">RECV_F</span>
<span class="n">SEND_B</span> <span class="o">=</span> <span class="n">_ComputationType</span><span class="o">.</span><span class="n">SEND_B</span>
<span class="n">RECV_B</span> <span class="o">=</span> <span class="n">_ComputationType</span><span class="o">.</span><span class="n">RECV_B</span>

<span class="c1"># Convenience shorthand for compute actions only since they are used in &#39;simple schedule format&#39;</span>
<span class="n">F</span> <span class="o">=</span> <span class="n">FORWARD</span>
<span class="n">B</span> <span class="o">=</span> <span class="n">BACKWARD</span>
<span class="n">W</span> <span class="o">=</span> <span class="n">WEIGHT</span>

<span class="c1"># Helper to parse an action string like 1F0 into a tuple of (stage_index, computation_type, microbatch_index)</span>
<span class="n">_action_regex</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span>
    <span class="sa">r</span><span class="s2">&quot;(\d+)([F,B,W]|UNSHARD|RESHARD|SEND_F|RECV_F|SEND_B|RECV_B{0,1})(\d*)&quot;</span>
<span class="p">)</span>


<span class="k">class</span> <span class="nc">_Action</span><span class="p">(</span><span class="n">NamedTuple</span><span class="p">):</span>
    <span class="n">stage_index</span><span class="p">:</span> <span class="nb">int</span>
    <span class="n">computation_type</span><span class="p">:</span> <span class="n">_ComputationType</span>
    <span class="n">microbatch_index</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">repr</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">stage_index</span><span class="p">)</span>
        <span class="nb">repr</span> <span class="o">+=</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">computation_type</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">microbatch_index</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="nb">repr</span> <span class="o">+=</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">microbatch_index</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">repr</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">from_str</span><span class="p">(</span><span class="nb">str</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Reverse of __repr__</span>

<span class="sd">        String should be formatted as [stage][action type][(microbatch)]</span>
<span class="sd">            e.g. `2F0`, `1UNSHARD`, `3SEND_F1`</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">match</span> <span class="o">:=</span> <span class="n">_action_regex</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="nb">str</span><span class="p">):</span>
            <span class="n">stage_index</span><span class="p">,</span> <span class="n">computation_type</span><span class="p">,</span> <span class="n">microbatch_index</span> <span class="o">=</span> <span class="n">match</span><span class="o">.</span><span class="n">groups</span><span class="p">()</span>
            <span class="k">return</span> <span class="n">_Action</span><span class="p">(</span>
                <span class="nb">int</span><span class="p">(</span><span class="n">stage_index</span><span class="p">),</span>
                <span class="n">_ComputationType</span><span class="o">.</span><span class="n">from_str</span><span class="p">(</span><span class="n">computation_type</span><span class="p">),</span>
                <span class="nb">int</span><span class="p">(</span><span class="n">microbatch_index</span><span class="p">)</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">microbatch_index</span><span class="p">)</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="nb">str</span> <span class="o">==</span> <span class="s2">&quot;&quot;</span> <span class="ow">or</span> <span class="nb">str</span><span class="o">.</span><span class="n">isspace</span><span class="p">():</span>
            <span class="k">return</span> <span class="kc">None</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Invalid action string: </span><span class="si">{</span><span class="nb">str</span><span class="si">}</span><span class="s2">, should be formatted as [stage][action type][(microbatch)] e.g. 2F0&quot;</span>
        <span class="p">)</span>


<span class="k">def</span> <span class="nf">_format_pipeline_order</span><span class="p">(</span><span class="n">pipeline_order</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Optional</span><span class="p">[</span><span class="n">_Action</span><span class="p">]]])</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Formats the pipeline order in a timestep (row) x rank (column) grid of actions</span>
<span class="sd">    and returns the formatted string</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># Calculate the maximum number of steps across all ranks</span>
    <span class="n">num_steps</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">actions</span><span class="p">)</span> <span class="k">for</span> <span class="n">actions</span> <span class="ow">in</span> <span class="n">pipeline_order</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
    <span class="n">step_labels</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s2">&quot;Step &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="o">.</span><span class="n">zfill</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">num_steps</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)))</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_steps</span><span class="p">)</span>
    <span class="p">]</span>
    <span class="c1"># Sorting the dictionary by keys and retrieving values in that order</span>
    <span class="n">rank_actions</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">pipeline_order</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;&quot;</span><span class="p">]</span> <span class="o">*</span> <span class="n">num_steps</span><span class="p">)</span> <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">pipeline_order</span><span class="p">)</span>
    <span class="p">]</span>
    <span class="c1"># Transpose the list of lists (rows to columns)</span>
    <span class="n">transposed_actions</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">itertools</span><span class="o">.</span><span class="n">zip_longest</span><span class="p">(</span><span class="o">*</span><span class="n">rank_actions</span><span class="p">,</span> <span class="n">fillvalue</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">))</span>
    <span class="c1"># Generate column labels for ranks</span>
    <span class="n">num_ranks</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">pipeline_order</span><span class="p">)</span>
    <span class="n">rank_labels</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Rank &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_ranks</span><span class="p">)]</span>
    <span class="c1"># Calculate the maximum length of each column, considering labels</span>
    <span class="n">max_lengths</span> <span class="o">=</span> <span class="p">[</span>
        <span class="nb">max</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">item</span><span class="p">))</span> <span class="k">if</span> <span class="n">item</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">col</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">step_labels</span><span class="p">,</span> <span class="o">*</span><span class="n">transposed_actions</span><span class="p">)</span>
    <span class="p">]</span>
    <span class="c1"># Format the header row with rank labels</span>
    <span class="n">header_row</span> <span class="o">=</span> <span class="s2">&quot; &quot;</span> <span class="o">*</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">step_labels</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">+</span> <span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">label</span><span class="si">:</span><span class="s2">&lt;</span><span class="si">{</span><span class="n">max_lengths</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">rank_labels</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="c1"># Format each row with its corresponding label</span>
    <span class="n">formatted_rows</span> <span class="o">=</span> <span class="p">[</span>
        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">label</span><span class="si">}</span><span class="s2">: &quot;</span>
        <span class="o">+</span> <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">item</span><span class="p">)</span><span class="si">:</span><span class="s2">&lt;</span><span class="si">{</span><span class="n">max_lengths</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">}}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">item</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">row</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">label</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">step_labels</span><span class="p">,</span> <span class="n">transposed_actions</span><span class="p">)</span>
    <span class="p">]</span>
    <span class="c1"># Join the rows into a single string</span>
    <span class="n">formatted_table</span> <span class="o">=</span> <span class="n">header_row</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">formatted_rows</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span>
    <span class="k">return</span> <span class="n">formatted_table</span>


<span class="k">def</span> <span class="nf">_validate_pipeline_order</span><span class="p">(</span>
    <span class="n">pipeline_order</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Optional</span><span class="p">[</span><span class="n">_Action</span><span class="p">]]],</span>
    <span class="n">num_microbatches</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">num_stages</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">enable_zero_bubble</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    pipeline_order[rank] = [(computation_type, microbatch_index, stage_index), ...]</span>
<span class="sd">    Validating that the pipeline order follows the rules:</span>
<span class="sd">    1. Forward action for a microbatch must be before the Backward action for that microbatch</span>
<span class="sd">    2. Recv for a microbatch must be before the send for that microbatch</span>
<span class="sd">    3. Microbatch index is handled in sequential order for each stage</span>
<span class="sd">    4. A later stage cannot operate on a microbatch before any of the previous stages have operated on it</span>
<span class="sd">    5. Same microbatch cannot be handled in the same time step across ranks</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># microbatch_index: (current computation type, current stage)</span>
    <span class="n">microbatch_process_info</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">_ComputationType</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">max_timestep</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">rank_list</span><span class="p">)</span> <span class="k">for</span> <span class="n">rank_list</span> <span class="ow">in</span> <span class="n">pipeline_order</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
    <span class="k">for</span> <span class="n">timestep</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_timestep</span><span class="p">):</span>
        <span class="n">error_msg</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">current_timestep_actions</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">rank</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">pipeline_order</span><span class="p">)):</span>
            <span class="n">action</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">pipeline_order</span><span class="p">[</span><span class="n">rank</span><span class="p">][</span><span class="n">timestep</span><span class="p">]</span>
                <span class="k">if</span> <span class="n">timestep</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">pipeline_order</span><span class="p">[</span><span class="n">rank</span><span class="p">])</span>
                <span class="k">else</span> <span class="kc">None</span>
            <span class="p">)</span>

            <span class="k">if</span> <span class="n">action</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">computation_type</span> <span class="o">=</span> <span class="n">action</span><span class="o">.</span><span class="n">computation_type</span>
                <span class="k">if</span> <span class="n">computation_type</span> <span class="o">!=</span> <span class="n">_ComputationType</span><span class="o">.</span><span class="n">WEIGHT</span><span class="p">:</span>
                    <span class="n">current_timestep_actions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>

        <span class="c1"># TODO: enable this</span>
        <span class="c1"># if len(current_timestep_actions) == 0:</span>
        <span class="c1">#     error_msg.append(</span>
        <span class="c1">#         &quot;All actions were None, there is an unnecessary gap in the schedule&quot;</span>
        <span class="c1">#     )</span>

        <span class="c1"># Ensure that no microbatch is operated on twice in current_timestep_actions</span>
        <span class="n">unique_microbatch_indices</span> <span class="o">=</span> <span class="p">{</span>
            <span class="n">action</span><span class="o">.</span><span class="n">microbatch_index</span> <span class="k">for</span> <span class="n">action</span> <span class="ow">in</span> <span class="n">current_timestep_actions</span>
        <span class="p">}</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">unique_microbatch_indices</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">current_timestep_actions</span><span class="p">):</span>
            <span class="n">error_msg</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="s2">&quot;Duplicate microbatch index found in current_timestep_actions&quot;</span>
            <span class="p">)</span>

        <span class="k">for</span> <span class="n">action</span> <span class="ow">in</span> <span class="n">current_timestep_actions</span><span class="p">:</span>
            <span class="n">stage_index</span> <span class="o">=</span> <span class="n">action</span><span class="o">.</span><span class="n">stage_index</span>
            <span class="n">computation_type</span> <span class="o">=</span> <span class="n">action</span><span class="o">.</span><span class="n">computation_type</span>
            <span class="n">mb_index</span> <span class="o">=</span> <span class="n">action</span><span class="o">.</span><span class="n">microbatch_index</span>
            <span class="k">assert</span> <span class="p">(</span>
                <span class="n">mb_index</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
            <span class="p">),</span> <span class="s2">&quot;All currently supported action types require valid microbatch_index&quot;</span>
            <span class="k">if</span> <span class="n">mb_index</span> <span class="o">&gt;=</span> <span class="n">num_microbatches</span><span class="p">:</span>
                <span class="n">error_msg</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Microbatch index </span><span class="si">{</span><span class="n">mb_index</span><span class="si">}</span><span class="s2"> out of range&quot;</span><span class="p">)</span>

            <span class="c1"># first microbatch</span>
            <span class="k">if</span> <span class="n">mb_index</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">microbatch_process_info</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">computation_type</span> <span class="o">!=</span> <span class="n">_ComputationType</span><span class="o">.</span><span class="n">FORWARD</span> <span class="ow">or</span> <span class="n">stage_index</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">error_msg</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Incorrect start for microbatch </span><span class="si">{</span><span class="n">mb_index</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="n">microbatch_process_info</span><span class="p">[</span><span class="n">mb_index</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">computation_type</span><span class="p">,</span> <span class="n">stage_index</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># if the microbatch is included, check that the current stage is right after prev</span>
                <span class="n">prev_computation</span><span class="p">,</span> <span class="n">prev_stage</span> <span class="o">=</span> <span class="n">microbatch_process_info</span><span class="p">[</span><span class="n">mb_index</span><span class="p">]</span>

                <span class="k">if</span> <span class="n">prev_computation</span> <span class="o">==</span> <span class="n">_ComputationType</span><span class="o">.</span><span class="n">FORWARD</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">prev_stage</span> <span class="o">==</span> <span class="n">num_stages</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
                        <span class="n">expected_stage</span> <span class="o">=</span> <span class="n">num_stages</span> <span class="o">-</span> <span class="mi">1</span>
                        <span class="n">expected_computation</span> <span class="o">=</span> <span class="n">_ComputationType</span><span class="o">.</span><span class="n">BACKWARD</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">expected_stage</span> <span class="o">=</span> <span class="n">prev_stage</span> <span class="o">+</span> <span class="mi">1</span>
                        <span class="n">expected_computation</span> <span class="o">=</span> <span class="n">_ComputationType</span><span class="o">.</span><span class="n">FORWARD</span>
                <span class="k">elif</span> <span class="n">prev_computation</span> <span class="o">==</span> <span class="n">_ComputationType</span><span class="o">.</span><span class="n">BACKWARD</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">prev_stage</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                        <span class="n">error_msg</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;[</span><span class="si">{</span><span class="n">mb_index</span><span class="si">=}</span><span class="s2">] already finished backward computation&quot;</span>
                        <span class="p">)</span>
                        <span class="k">break</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">expected_stage</span> <span class="o">=</span> <span class="n">prev_stage</span> <span class="o">-</span> <span class="mi">1</span>
                        <span class="n">expected_computation</span> <span class="o">=</span> <span class="n">_ComputationType</span><span class="o">.</span><span class="n">BACKWARD</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;Computation type </span><span class="si">{</span><span class="n">prev_computation</span><span class="si">}</span><span class="s2"> not supported&quot;</span>
                    <span class="p">)</span>

                <span class="k">if</span> <span class="n">expected_computation</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">expected_computation</span> <span class="o">!=</span> <span class="n">computation_type</span><span class="p">:</span>
                        <span class="n">error_msg</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;[</span><span class="si">{</span><span class="n">mb_index</span><span class="si">=}</span><span class="s2">] </span><span class="si">{</span><span class="n">expected_computation</span><span class="si">=}</span><span class="s2"> VS. actual </span><span class="si">{</span><span class="n">computation_type</span><span class="si">=}</span><span class="s2">&quot;</span>
                        <span class="p">)</span>

                <span class="k">if</span> <span class="n">expected_stage</span> <span class="o">!=</span> <span class="n">stage_index</span><span class="p">:</span>
                    <span class="n">error_msg</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;[</span><span class="si">{</span><span class="n">mb_index</span><span class="si">=}</span><span class="s2">] </span><span class="si">{</span><span class="n">expected_stage</span><span class="si">=}</span><span class="s2"> VS. actual </span><span class="si">{</span><span class="n">stage_index</span><span class="si">=}</span><span class="s2">&quot;</span>
                    <span class="p">)</span>

                <span class="n">microbatch_process_info</span><span class="p">[</span><span class="n">mb_index</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="n">expected_computation</span><span class="p">,</span>
                    <span class="n">expected_stage</span><span class="p">,</span>
                <span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">enable_zero_bubble</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">error_msg</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Error at timestep </span><span class="si">{</span><span class="n">timestep</span><span class="si">}</span><span class="s2">: &quot;</span> <span class="o">+</span> <span class="s2">&quot;,&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">error_msg</span><span class="p">)</span>
                <span class="p">)</span>
            <span class="k">return</span>

        <span class="k">for</span> <span class="n">rank</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">pipeline_order</span><span class="p">)):</span>
            <span class="n">backward_steps</span><span class="p">:</span> <span class="n">Set</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
            <span class="n">weight_steps</span><span class="p">:</span> <span class="n">Set</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>

            <span class="k">for</span> <span class="n">action</span> <span class="ow">in</span> <span class="n">pipeline_order</span><span class="p">[</span><span class="n">rank</span><span class="p">]:</span>
                <span class="k">if</span> <span class="n">action</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="k">continue</span>

                <span class="n">stage_index</span> <span class="o">=</span> <span class="n">action</span><span class="o">.</span><span class="n">stage_index</span>
                <span class="n">computation_type</span> <span class="o">=</span> <span class="n">action</span><span class="o">.</span><span class="n">computation_type</span>
                <span class="n">mb_index</span> <span class="o">=</span> <span class="n">action</span><span class="o">.</span><span class="n">microbatch_index</span>
                <span class="k">if</span> <span class="n">computation_type</span> <span class="o">==</span> <span class="n">_ComputationType</span><span class="o">.</span><span class="n">BACKWARD</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">mb_index</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="n">backward_steps</span><span class="o">.</span><span class="n">add</span><span class="p">((</span><span class="n">mb_index</span><span class="p">,</span> <span class="n">stage_index</span><span class="p">))</span>
                <span class="k">elif</span> <span class="n">computation_type</span> <span class="o">==</span> <span class="n">_ComputationType</span><span class="o">.</span><span class="n">WEIGHT</span><span class="p">:</span>
                    <span class="k">if</span> <span class="p">(</span><span class="n">mb_index</span><span class="p">,</span> <span class="n">stage_index</span><span class="p">)</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">backward_steps</span><span class="p">:</span>
                        <span class="n">error_msg</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">mb_index</span><span class="si">=}</span><span class="s2">, </span><span class="si">{</span><span class="n">stage_index</span><span class="si">=}</span><span class="s2"> Weight happened before bwd&quot;</span>
                        <span class="p">)</span>
                    <span class="k">if</span> <span class="p">(</span><span class="n">mb_index</span><span class="p">,</span> <span class="n">stage_index</span><span class="p">)</span> <span class="ow">in</span> <span class="n">weight_steps</span><span class="p">:</span>
                        <span class="n">error_msg</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">mb_index</span><span class="si">=}</span><span class="s2">, </span><span class="si">{</span><span class="n">stage_index</span><span class="si">=}</span><span class="s2"> Duplicated weight step&quot;</span>
                        <span class="p">)</span>
                    <span class="k">if</span> <span class="n">mb_index</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="n">weight_steps</span><span class="o">.</span><span class="n">add</span><span class="p">((</span><span class="n">mb_index</span><span class="p">,</span> <span class="n">stage_index</span><span class="p">))</span>

            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">backward_steps</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">weight_steps</span><span class="p">):</span>
                <span class="n">error_msg</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;Length weight steps != Length bwd steps&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">error_msg</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Error at timestep </span><span class="si">{</span><span class="n">timestep</span><span class="si">}</span><span class="s2">: &quot;</span> <span class="o">+</span> <span class="s2">&quot;,&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">error_msg</span><span class="p">))</span>


<span class="k">class</span> <span class="nc">_PipelineSchedule</span><span class="p">(</span><span class="n">ABC</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">n_microbatches</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">loss_fn</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">args_chunk_spec</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">TensorChunkSpec</span><span class="p">,</span> <span class="o">...</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">kwargs_chunk_spec</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">TensorChunkSpec</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">output_merge_spec</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Any</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="c1"># From arguments</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_n_microbatches</span> <span class="o">=</span> <span class="n">n_microbatches</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_loss_fn</span> <span class="o">=</span> <span class="n">loss_fn</span>
        <span class="c1"># Chunking specification for positional inputs. (default: `None`)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_args_chunk_spec</span> <span class="o">=</span> <span class="n">args_chunk_spec</span>
        <span class="c1"># Chunking specification for keyword inputs. (default: `None`)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_kwargs_chunk_spec</span> <span class="o">=</span> <span class="n">kwargs_chunk_spec</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_output_merge_spec</span> <span class="o">=</span> <span class="n">output_merge_spec</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        # args_chunk_spec and kwargs_chunk_spec specify how to chunk inputs.</span>
<span class="sd">        # They are used to convert batch to microbatches in `step(x)`.  See</span>
<span class="sd">        # `TensorChunkSpec` for helper methods for creating them.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># Derived</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_has_backward</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_loss_fn</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>

        <span class="c1"># Holds the losses for each microbatch.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_internal_losses</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Using </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_maybe_compute_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">stage</span><span class="p">,</span> <span class="n">output</span><span class="p">,</span> <span class="n">target_mbs</span><span class="p">,</span> <span class="n">mb_index</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">stage</span><span class="o">.</span><span class="n">is_last</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_has_backward</span><span class="p">:</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_loss</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target_mbs</span><span class="p">[</span><span class="n">mb_index</span><span class="p">])</span>  <span class="c1"># type: ignore[index]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_internal_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_maybe_get_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">stage</span><span class="p">,</span> <span class="n">mb_index</span><span class="p">):</span>
        <span class="n">valid_index</span> <span class="o">=</span> <span class="mi">0</span> <span class="o">&lt;=</span> <span class="n">mb_index</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_internal_losses</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">stage</span><span class="o">.</span><span class="n">is_last</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_has_backward</span> <span class="ow">and</span> <span class="n">valid_index</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_internal_losses</span><span class="p">[</span><span class="n">mb_index</span><span class="p">]</span>
        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_internal_losses</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">0</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">valid_index</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Loss for microbatch </span><span class="si">{</span><span class="n">mb_index</span><span class="si">}</span><span class="s2"> is not available. &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;Available losses for microbatches: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_internal_losses</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">_update_losses</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">stages</span><span class="p">,</span> <span class="n">losses</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Update the losses to those in the internal state</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># if stages not a list turn into a list</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">stages</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">stages</span> <span class="o">=</span> <span class="p">[</span><span class="n">stages</span><span class="p">]</span>
        <span class="n">contains_last_stage</span> <span class="o">=</span> <span class="nb">any</span><span class="p">(</span><span class="n">stage</span><span class="o">.</span><span class="n">is_last</span> <span class="k">for</span> <span class="n">stage</span> <span class="ow">in</span> <span class="n">stages</span><span class="p">)</span>

        <span class="c1"># Return losses if there is a container passed in</span>
        <span class="k">if</span> <span class="n">contains_last_stage</span> <span class="ow">and</span> <span class="n">losses</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_internal_losses</span><span class="p">)</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_n_microbatches</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Expecting </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_n_microbatches</span><span class="si">}</span><span class="s2"> losses but got </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_internal_losses</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>

            <span class="c1"># Clean external container first</span>
            <span class="n">losses</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>
            <span class="c1"># Copy internal losses to external container</span>
            <span class="n">losses</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_internal_losses</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_internal_losses</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>

    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">_step_microbatches</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">arg_mbs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">kwarg_mbs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">target_mbs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">losses</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Run one iteration of the pipeline schedule with list of microbatches.</span>
<span class="sd">        Will go through all the microbatches according to the schedule</span>
<span class="sd">        implementation.</span>

<span class="sd">        Args:</span>
<span class="sd">            microbatches: list of microbatch args.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">losses</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Run one iteration of the pipeline schedule with *whole-batch* input.</span>
<span class="sd">        Will chunk the input into microbatches automatically, and go through the</span>
<span class="sd">        microbatches according to the schedule implementation.</span>

<span class="sd">        args: positional arguments to the model (as in non-pipeline case).</span>
<span class="sd">        kwargs: keyword arguments to the model (as in non-pipeline case).</span>
<span class="sd">        target: target for the loss function.</span>
<span class="sd">        losses: a list to store the losses for each microbatch.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span>

    <span class="k">def</span> <span class="nf">_check_inputs</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">arg_mbs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">kwarg_mbs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">target_mbs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">losses</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Pre-process/check inputs</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">def</span> <span class="nf">check_type_and_len</span><span class="p">(</span><span class="n">mbs</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">mbs</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2"> must be a list but got a </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">mbs</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">mbs</span><span class="p">)</span> <span class="o">!=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_n_microbatches</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Expecting </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_n_microbatches</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2"> but got </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">mbs</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>

        <span class="k">if</span> <span class="n">arg_mbs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">check_type_and_len</span><span class="p">(</span><span class="n">arg_mbs</span><span class="p">,</span> <span class="s2">&quot;arg_mbs&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">arg_mbs</span> <span class="o">=</span> <span class="p">[()]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">_n_microbatches</span>

        <span class="k">if</span> <span class="n">kwarg_mbs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">check_type_and_len</span><span class="p">(</span><span class="n">kwarg_mbs</span><span class="p">,</span> <span class="s2">&quot;kwarg_mbs&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">kwarg_mbs</span> <span class="o">=</span> <span class="p">[{}]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">_n_microbatches</span>

        <span class="k">if</span> <span class="n">target_mbs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">check_type_and_len</span><span class="p">(</span><span class="n">target_mbs</span><span class="p">,</span> <span class="s2">&quot;target_mbs&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">losses</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">losses</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;losses must be a list but got a </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">losses</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">arg_mbs</span><span class="p">,</span> <span class="n">kwarg_mbs</span>

    <span class="k">def</span> <span class="nf">_compute_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_loss_fn</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>  <span class="c1"># type: ignore[misc]</span>

    <span class="k">def</span> <span class="nf">_split_inputs</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">args</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span>
        <span class="n">kwargs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Splits a full-batch input into chunks (i.e. microbatches) and returns</span>
<span class="sd">        the chunks</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">args</span> <span class="ow">or</span> <span class="n">kwargs</span><span class="p">:</span>
            <span class="n">args_split</span><span class="p">,</span> <span class="n">kwargs_split</span> <span class="o">=</span> <span class="n">split_args_kwargs_into_chunks</span><span class="p">(</span>
                <span class="n">args</span><span class="p">,</span>
                <span class="n">kwargs</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_n_microbatches</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_args_chunk_spec</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_kwargs_chunk_spec</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">return</span> <span class="n">args_split</span><span class="p">,</span> <span class="n">kwargs_split</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Empty inputs (e.g. when called on middle stages)</span>
            <span class="c1"># Return a list of empty tuples/dicts with matching length as chunks</span>
            <span class="k">return</span> <span class="p">[()]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">_n_microbatches</span><span class="p">,</span> <span class="p">[{}]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">_n_microbatches</span>

    <span class="k">def</span> <span class="nf">_merge_outputs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_chunks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Any</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Merge output chunks back to a batch state.</span>
<span class="sd">        If output_merge_spec is None, the utility will merge output chunks by dimension 0 (batch dim).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">merge_chunks</span><span class="p">(</span>
            <span class="n">output_chunks</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_output_merge_spec</span><span class="p">,</span>
        <span class="p">)</span>


<span class="k">def</span> <span class="nf">_batch_p2p</span><span class="p">(</span><span class="n">p2p_ops</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">dist</span><span class="o">.</span><span class="n">P2POp</span><span class="p">],</span> <span class="n">desc</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Simple wrapper over batch_isend_irecv from torch.distributed, which just adds a descriptive logger on top.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">p2p_ops</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">None</span>
    <span class="n">desc_str</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">desc</span><span class="si">}</span><span class="s2">, &quot;</span> <span class="k">if</span> <span class="n">desc</span> <span class="k">else</span> <span class="s2">&quot;&quot;</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;batch_p2p </span><span class="si">%s%s</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">desc_str</span><span class="p">,</span> <span class="n">p2p_ops</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">dist</span><span class="o">.</span><span class="n">batch_isend_irecv</span><span class="p">(</span><span class="n">p2p_ops</span><span class="p">)</span><span class="o">.</span><span class="n">pop</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">_sorted_batch_p2p</span><span class="p">(</span>
    <span class="n">p2p_ops</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">dist</span><span class="o">.</span><span class="n">P2POp</span><span class="p">],</span> <span class="n">desc</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">dist</span><span class="o">.</span><span class="n">Work</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Sorts the list of P2P ops by the peer rank, and then calls</span>
<span class="sd">    batch_isend_irecv. Return a dictionary of works by peer rank. This function</span>
<span class="sd">    helps us avoid hangs in case of skip connections.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Arrange p2p_ops by peer rank:</span>
    <span class="c1">#   int is the peer rank;</span>
    <span class="c1">#   List is the list of ops towards the peer</span>
    <span class="n">ops_by_peer</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">dist</span><span class="o">.</span><span class="n">P2POp</span><span class="p">]]</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">list</span><span class="p">)</span>
    <span class="n">work_by_peer</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">dist</span><span class="o">.</span><span class="n">Work</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">p2p_ops</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">work_by_peer</span>

    <span class="c1"># Classify the ops by peer rank</span>
    <span class="k">for</span> <span class="n">op</span> <span class="ow">in</span> <span class="n">p2p_ops</span><span class="p">:</span>
        <span class="n">ops_by_peer</span><span class="p">[</span><span class="n">op</span><span class="o">.</span><span class="n">peer</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>

    <span class="c1"># Call batch_isend_irecv per peer, in sorted order of the peers (to avoid hangs)</span>
    <span class="k">for</span> <span class="n">peer</span><span class="p">,</span> <span class="n">ops</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">ops_by_peer</span><span class="o">.</span><span class="n">items</span><span class="p">()):</span>
        <span class="n">work_by_peer</span><span class="p">[</span><span class="n">peer</span><span class="p">]</span> <span class="o">=</span> <span class="n">_batch_p2p</span><span class="p">(</span><span class="n">ops</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="n">desc</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">work_by_peer</span>


<div class="viewcode-block" id="PipelineScheduleSingle"><a class="viewcode-back" href="../../../../distributed.pipelining.html#torch.distributed.pipelining.schedules.PipelineScheduleSingle">[docs]</a><span class="k">class</span> <span class="nc">PipelineScheduleSingle</span><span class="p">(</span><span class="n">_PipelineSchedule</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Base class for single-stage schedules.</span>
<span class="sd">    Implements the `step` method.</span>
<span class="sd">    Derived classes should implement `_step_microbatches`.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">stage</span><span class="p">:</span> <span class="n">_PipelineStageBase</span><span class="p">,</span>
        <span class="n">n_microbatches</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">loss_fn</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">args_chunk_spec</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">TensorChunkSpec</span><span class="p">,</span> <span class="o">...</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">kwargs_chunk_spec</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">TensorChunkSpec</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">output_merge_spec</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Any</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="c1"># Init parent</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">n_microbatches</span><span class="o">=</span><span class="n">n_microbatches</span><span class="p">,</span>
            <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss_fn</span><span class="p">,</span>
            <span class="n">args_chunk_spec</span><span class="o">=</span><span class="n">args_chunk_spec</span><span class="p">,</span>
            <span class="n">kwargs_chunk_spec</span><span class="o">=</span><span class="n">kwargs_chunk_spec</span><span class="p">,</span>
            <span class="n">output_merge_spec</span><span class="o">=</span><span class="n">output_merge_spec</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="c1"># Self attributes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_stage</span> <span class="o">=</span> <span class="n">stage</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_num_stages</span> <span class="o">=</span> <span class="n">stage</span><span class="o">.</span><span class="n">num_stages</span>
        <span class="c1"># Set the same has_backward flag for stage object</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_stage</span><span class="o">.</span><span class="n">has_backward</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_has_backward</span>

        <span class="c1"># TODO: later replace this with lazy shape inference during forward</span>
        <span class="c1"># Prepare forward send/recv infrastructure for stage</span>
        <span class="n">stage</span><span class="o">.</span><span class="n">_prepare_forward_infra</span><span class="p">(</span><span class="n">n_microbatches</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_has_backward</span><span class="p">:</span>
            <span class="n">stage</span><span class="o">.</span><span class="n">_prepare_backward_infra</span><span class="p">(</span><span class="n">n_microbatches</span><span class="p">)</span>

<div class="viewcode-block" id="PipelineScheduleSingle.step"><a class="viewcode-back" href="../../../../distributed.pipelining.html#torch.distributed.pipelining.schedules.PipelineScheduleSingle.step">[docs]</a>    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">losses</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Run one iteration of the pipeline schedule with *whole-batch* input.</span>
<span class="sd">        Will chunk the input into microbatches automatically, and go through the</span>
<span class="sd">        microbatches according to the schedule implementation.</span>

<span class="sd">        args: positional arguments to the model (as in non-pipeline case).</span>
<span class="sd">        kwargs: keyword arguments to the model (as in non-pipeline case).</span>
<span class="sd">        target: target for the loss function.</span>
<span class="sd">        losses: a list to store the losses for each microbatch.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># Clean per iteration</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_stage</span><span class="o">.</span><span class="n">clear_runtime_states</span><span class="p">()</span>

        <span class="c1"># Split inputs into microbatches</span>
        <span class="n">args_split</span><span class="p">,</span> <span class="n">kwargs_split</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_split_inputs</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">)</span>

        <span class="c1"># Split target into microbatches</span>
        <span class="k">if</span> <span class="n">target</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">targets_split</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor_split</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_n_microbatches</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">targets_split</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># Run microbatches</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_step_microbatches</span><span class="p">(</span><span class="n">args_split</span><span class="p">,</span> <span class="n">kwargs_split</span><span class="p">,</span> <span class="n">targets_split</span><span class="p">,</span> <span class="n">losses</span><span class="p">)</span>

        <span class="c1"># Return merged results per original format</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stage</span><span class="o">.</span><span class="n">is_last</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_merge_outputs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_stage</span><span class="o">.</span><span class="n">output_chunks</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">None</span></div></div>


<span class="k">class</span> <span class="nc">_ScheduleForwardOnly</span><span class="p">(</span><span class="n">PipelineScheduleSingle</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The forward-only schedule.</span>
<span class="sd">    Will go through all the microbatches and perform only the forward pass</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">_step_microbatches</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">arg_mbs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">kwarg_mbs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">target_mbs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">losses</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Run one iteration of the pipeline schedule</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">target_mbs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">losses</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="s2">&quot;Forward-only schedule does not support loss computation&quot;</span>
            <span class="p">)</span>

        <span class="n">arg_mbs</span><span class="p">,</span> <span class="n">kwarg_mbs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_check_inputs</span><span class="p">(</span><span class="n">arg_mbs</span><span class="p">,</span> <span class="n">kwarg_mbs</span><span class="p">,</span> <span class="n">target_mbs</span><span class="p">,</span> <span class="n">losses</span><span class="p">)</span>

        <span class="c1"># Delay send waits</span>
        <span class="n">fwd_sends_to_wait</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">dist</span><span class="o">.</span><span class="n">Work</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># Run microbatches</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_n_microbatches</span><span class="p">):</span>
            <span class="k">with</span> <span class="n">record_function</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Forward </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">):</span>
                <span class="n">ops</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stage</span><span class="o">.</span><span class="n">get_fwd_recv_ops</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
                <span class="n">works</span> <span class="o">=</span> <span class="n">_sorted_batch_p2p</span><span class="p">(</span><span class="n">ops</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;fwd_recv&quot;</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">work</span> <span class="ow">in</span> <span class="n">works</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
                    <span class="n">work</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">_stage</span><span class="o">.</span><span class="n">forward_one_chunk</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">arg_mbs</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">kwarg_mbs</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>  <span class="c1"># type: ignore[index]</span>

                <span class="n">ops</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stage</span><span class="o">.</span><span class="n">get_fwd_send_ops</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
                <span class="n">works</span> <span class="o">=</span> <span class="n">_sorted_batch_p2p</span><span class="p">(</span><span class="n">ops</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;fwd_send&quot;</span><span class="p">)</span>
                <span class="n">fwd_sends_to_wait</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">works</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;[</span><span class="si">%s</span><span class="s2">] Forwarded microbatch </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stage</span><span class="o">.</span><span class="n">stage_index</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>

        <span class="c1"># Wait for all forward sends to finish</span>
        <span class="c1"># This should not have performance impact because by the time the first</span>
        <span class="c1"># backward arrives all the forward sends should have been finished.</span>
        <span class="k">for</span> <span class="n">work</span> <span class="ow">in</span> <span class="n">fwd_sends_to_wait</span><span class="p">:</span>
            <span class="n">work</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>


<div class="viewcode-block" id="ScheduleGPipe"><a class="viewcode-back" href="../../../../distributed.pipelining.html#torch.distributed.pipelining.schedules.ScheduleGPipe">[docs]</a><span class="k">class</span> <span class="nc">ScheduleGPipe</span><span class="p">(</span><span class="n">PipelineScheduleSingle</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The GPipe schedule.</span>
<span class="sd">    Will go through all the microbatches in a fill-drain manner.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">_step_microbatches</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">arg_mbs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">kwarg_mbs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">target_mbs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">losses</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Run one iteration of the pipeline schedule with list of microbatches.</span>
<span class="sd">        Will go through all the microbatches according to the GPipe schedule.</span>

<span class="sd">        Args:</span>
<span class="sd">            microbatches: list of microbatch args.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">arg_mbs</span><span class="p">,</span> <span class="n">kwarg_mbs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_check_inputs</span><span class="p">(</span><span class="n">arg_mbs</span><span class="p">,</span> <span class="n">kwarg_mbs</span><span class="p">,</span> <span class="n">target_mbs</span><span class="p">,</span> <span class="n">losses</span><span class="p">)</span>

        <span class="c1"># Delay send waits</span>
        <span class="n">fwd_sends_to_wait</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">dist</span><span class="o">.</span><span class="n">Work</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="c1"># Run microbatches</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_n_microbatches</span><span class="p">):</span>
            <span class="k">with</span> <span class="n">record_function</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Forward </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">):</span>
                <span class="n">ops</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stage</span><span class="o">.</span><span class="n">get_fwd_recv_ops</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
                <span class="n">works</span> <span class="o">=</span> <span class="n">_sorted_batch_p2p</span><span class="p">(</span><span class="n">ops</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;fwd_recv&quot;</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">work</span> <span class="ow">in</span> <span class="n">works</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
                    <span class="n">work</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>

                <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stage</span><span class="o">.</span><span class="n">forward_one_chunk</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">arg_mbs</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">kwarg_mbs</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>  <span class="c1"># type: ignore[index]</span>

                <span class="n">ops</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stage</span><span class="o">.</span><span class="n">get_fwd_send_ops</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
                <span class="n">works</span> <span class="o">=</span> <span class="n">_sorted_batch_p2p</span><span class="p">(</span><span class="n">ops</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;fwd_send&quot;</span><span class="p">)</span>
                <span class="n">fwd_sends_to_wait</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">works</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;[</span><span class="si">%s</span><span class="s2">] Forwarded microbatch </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stage</span><span class="o">.</span><span class="n">stage_index</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">_maybe_compute_loss</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_stage</span><span class="p">,</span> <span class="n">output</span><span class="p">,</span> <span class="n">target_mbs</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>

        <span class="c1"># Wait for all forward sends to finish</span>
        <span class="c1"># This should not have performance impact because by the time the first</span>
        <span class="c1"># backward arrives all the forward sends should have been finished.</span>
        <span class="k">for</span> <span class="n">work</span> <span class="ow">in</span> <span class="n">fwd_sends_to_wait</span><span class="p">:</span>
            <span class="n">work</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>

        <span class="c1"># No loss function, no need to run backward</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_has_backward</span><span class="p">:</span>
            <span class="k">return</span>

        <span class="c1"># Run backward</span>
        <span class="c1"># Delay send waits</span>
        <span class="n">bwd_sends_to_wait</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">dist</span><span class="o">.</span><span class="n">Work</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_n_microbatches</span><span class="p">):</span>
            <span class="k">with</span> <span class="n">record_function</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Backward </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">):</span>
                <span class="n">ops</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stage</span><span class="o">.</span><span class="n">get_bwd_recv_ops</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
                <span class="n">works</span> <span class="o">=</span> <span class="n">_sorted_batch_p2p</span><span class="p">(</span><span class="n">ops</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;bwd_recv&quot;</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">work</span> <span class="ow">in</span> <span class="n">works</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
                    <span class="n">work</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>

                <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_maybe_get_loss</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_stage</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_stage</span><span class="o">.</span><span class="n">backward_one_chunk</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">)</span>

                <span class="n">ops</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stage</span><span class="o">.</span><span class="n">get_bwd_send_ops</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
                <span class="n">works</span> <span class="o">=</span> <span class="n">_sorted_batch_p2p</span><span class="p">(</span><span class="n">ops</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;bwd_send&quot;</span><span class="p">)</span>
                <span class="n">bwd_sends_to_wait</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">works</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>

            <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;[</span><span class="si">%s</span><span class="s2">] Backwarded microbatch </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stage</span><span class="o">.</span><span class="n">stage_index</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>

        <span class="c1"># Return losses if there is a container passed in</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_update_losses</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_stage</span><span class="p">,</span> <span class="n">losses</span><span class="p">)</span>

        <span class="c1"># Wait for all backward sends to finish</span>
        <span class="k">for</span> <span class="n">work</span> <span class="ow">in</span> <span class="n">bwd_sends_to_wait</span><span class="p">:</span>
            <span class="n">work</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span></div>


<div class="viewcode-block" id="Schedule1F1B"><a class="viewcode-back" href="../../../../distributed.pipelining.html#torch.distributed.pipelining.schedules.Schedule1F1B">[docs]</a><span class="k">class</span> <span class="nc">Schedule1F1B</span><span class="p">(</span><span class="n">PipelineScheduleSingle</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The 1F1B schedule.</span>
<span class="sd">    Will perform one forward and one backward on the microbatches in steady state.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">_step_microbatches</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">arg_mbs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">kwarg_mbs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">target_mbs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">losses</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Run one iteration of the pipeline schedule with list of microbatches.</span>
<span class="sd">        Will go through all the microbatches according to the 1F1B schedule.</span>

<span class="sd">        Args:</span>
<span class="sd">            microbatches: list of microbatch args.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">arg_mbs</span><span class="p">,</span> <span class="n">kwarg_mbs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_check_inputs</span><span class="p">(</span><span class="n">arg_mbs</span><span class="p">,</span> <span class="n">kwarg_mbs</span><span class="p">,</span> <span class="n">target_mbs</span><span class="p">,</span> <span class="n">losses</span><span class="p">)</span>

        <span class="c1"># Last stage has 1 warmup, second-to-last 2 warmups, ...</span>
        <span class="c1"># first stage `num_stages` warmups</span>
        <span class="n">warmup_chunks</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_n_microbatches</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_num_stages</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stage</span><span class="o">.</span><span class="n">stage_index</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># Chunk counters</span>
        <span class="n">fwd_mb_index</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">bwd_mb_index</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">weight_stage_mb_index</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="c1"># Warmup phase</span>
        <span class="n">send_work</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">fwd_sends</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">warmup_chunks</span><span class="p">):</span>
            <span class="c1"># Receive activations</span>
            <span class="n">fwd_recvs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stage</span><span class="o">.</span><span class="n">get_fwd_recv_ops</span><span class="p">(</span><span class="n">fwd_mb_index</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">recv_work</span> <span class="o">:=</span> <span class="n">_batch_p2p</span><span class="p">(</span><span class="n">fwd_recvs</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;fwd_recv&quot;</span><span class="p">):</span>
                <span class="n">recv_work</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>

            <span class="c1"># Compute</span>
            <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stage</span><span class="o">.</span><span class="n">forward_one_chunk</span><span class="p">(</span><span class="n">fwd_mb_index</span><span class="p">,</span> <span class="n">arg_mbs</span><span class="p">[</span><span class="n">fwd_mb_index</span><span class="p">],</span> <span class="n">kwarg_mbs</span><span class="p">[</span><span class="n">fwd_mb_index</span><span class="p">])</span>  <span class="c1"># type: ignore[index]</span>

            <span class="c1"># Clear previous chunk&#39;s forward sends (hopefully they have well</span>
            <span class="c1"># finished, otherwise, we are heavily communication bound, in which</span>
            <span class="c1"># case it doesn&#39;t create a lot of benefit to compute next chunk</span>
            <span class="c1"># eagerly either)</span>
            <span class="k">if</span> <span class="n">send_work</span><span class="p">:</span>
                <span class="n">send_work</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>

            <span class="c1"># Send activations</span>
            <span class="n">fwd_sends</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stage</span><span class="o">.</span><span class="n">get_fwd_send_ops</span><span class="p">(</span><span class="n">fwd_mb_index</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">fwd_mb_index</span> <span class="o">!=</span> <span class="n">warmup_chunks</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
                <span class="c1"># Safe to fire</span>
                <span class="n">send_work</span> <span class="o">=</span> <span class="n">_batch_p2p</span><span class="p">(</span><span class="n">fwd_sends</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;fwd_send&quot;</span><span class="p">)</span>
            <span class="c1"># otherwise:</span>
            <span class="c1">#   The last foward send is left for fuse with first 1B in 1B1F below</span>

            <span class="c1"># Compute loss</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_maybe_compute_loss</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_stage</span><span class="p">,</span> <span class="n">output</span><span class="p">,</span> <span class="n">target_mbs</span><span class="p">,</span> <span class="n">fwd_mb_index</span><span class="p">)</span>
            <span class="n">fwd_mb_index</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="c1"># Now we should have send ops left over, to be fused with first 1B of 1B1F phase below.</span>

        <span class="c1"># 1B1F phase</span>
        <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>  <span class="c1"># Don&#39;t worry, we have a break inside</span>
            <span class="c1"># We actually do 1B first as the `1B1F` name indicates, so prepare its recv ops</span>
            <span class="n">bwd_recvs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stage</span><span class="o">.</span><span class="n">get_bwd_recv_ops</span><span class="p">(</span><span class="n">bwd_mb_index</span><span class="p">)</span>

            <span class="c1"># Now, we need to fire the fwd_sends and bwd_recvs together</span>
            <span class="k">if</span> <span class="n">fuse_work</span> <span class="o">:=</span> <span class="n">_batch_p2p</span><span class="p">(</span><span class="n">fwd_sends</span> <span class="o">+</span> <span class="n">bwd_recvs</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;fwd_send_bwd_recv&quot;</span><span class="p">):</span>
                <span class="n">fuse_work</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>

            <span class="c1"># Backward one chunk</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_maybe_get_loss</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_stage</span><span class="p">,</span> <span class="n">bwd_mb_index</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_stage</span><span class="o">.</span><span class="n">backward_one_chunk</span><span class="p">(</span><span class="n">bwd_mb_index</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">)</span>

            <span class="c1"># Get the bwd send ops, but don&#39;t fire, to be fused with the 1F below</span>
            <span class="n">bwd_sends</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stage</span><span class="o">.</span><span class="n">get_bwd_send_ops</span><span class="p">(</span><span class="n">bwd_mb_index</span><span class="p">)</span>
            <span class="n">bwd_mb_index</span> <span class="o">+=</span> <span class="mi">1</span>

            <span class="k">if</span> <span class="n">fwd_mb_index</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">_n_microbatches</span><span class="p">:</span>
                <span class="c1"># We are done with 1B1F, so break with some left-over bwd_sends</span>
                <span class="k">break</span>

            <span class="c1"># We prepare 1F of the `1B1F`</span>
            <span class="n">fwd_recvs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stage</span><span class="o">.</span><span class="n">get_fwd_recv_ops</span><span class="p">(</span><span class="n">fwd_mb_index</span><span class="p">)</span>

            <span class="c1"># Fuse it with bwd_sends above</span>
            <span class="k">if</span> <span class="n">fuse_work</span> <span class="o">:=</span> <span class="n">_batch_p2p</span><span class="p">(</span><span class="n">bwd_sends</span> <span class="o">+</span> <span class="n">fwd_recvs</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;bwd_send_fwd_recv&quot;</span><span class="p">):</span>
                <span class="n">fuse_work</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>

            <span class="c1"># Now do the fwd</span>
            <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stage</span><span class="o">.</span><span class="n">forward_one_chunk</span><span class="p">(</span><span class="n">fwd_mb_index</span><span class="p">,</span> <span class="n">arg_mbs</span><span class="p">[</span><span class="n">fwd_mb_index</span><span class="p">],</span> <span class="n">kwarg_mbs</span><span class="p">[</span><span class="n">fwd_mb_index</span><span class="p">])</span>  <span class="c1"># type: ignore[index]</span>

            <span class="c1"># Compute loss</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_maybe_compute_loss</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_stage</span><span class="p">,</span> <span class="n">output</span><span class="p">,</span> <span class="n">target_mbs</span><span class="p">,</span> <span class="n">fwd_mb_index</span><span class="p">)</span>

            <span class="c1"># Get the fwd send ops, but don&#39;t fire, leave it for the next iter (wrap-around)</span>
            <span class="n">fwd_sends</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stage</span><span class="o">.</span><span class="n">get_fwd_send_ops</span><span class="p">(</span><span class="n">fwd_mb_index</span><span class="p">)</span>
            <span class="n">fwd_mb_index</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="c1"># Remember we still have some bwd_sends left over after the break? Now it is time to fire it</span>
        <span class="n">send_work</span> <span class="o">=</span> <span class="n">_batch_p2p</span><span class="p">(</span><span class="n">bwd_sends</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;bwd_send&quot;</span><span class="p">)</span>

        <span class="c1"># Cooldown</span>
        <span class="k">while</span> <span class="n">bwd_mb_index</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">_n_microbatches</span><span class="p">:</span>
            <span class="c1"># prepare bwd recv ops</span>
            <span class="n">bwd_recvs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stage</span><span class="o">.</span><span class="n">get_bwd_recv_ops</span><span class="p">(</span><span class="n">bwd_mb_index</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">recv_work</span> <span class="o">:=</span> <span class="n">_batch_p2p</span><span class="p">(</span><span class="n">bwd_recvs</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;bwd_recv&quot;</span><span class="p">):</span>
                <span class="n">recv_work</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>

            <span class="c1"># Backward one chunk</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_maybe_get_loss</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_stage</span><span class="p">,</span> <span class="n">bwd_mb_index</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_stage</span><span class="o">.</span><span class="n">backward_one_chunk</span><span class="p">(</span><span class="n">bwd_mb_index</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">)</span>

            <span class="c1"># Clear previous chunk&#39;s backward sends (hopefully they have well finished)</span>
            <span class="k">if</span> <span class="n">send_work</span><span class="p">:</span>
                <span class="n">send_work</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>

            <span class="c1"># Get the bwd send ops, fire it</span>
            <span class="n">bwd_sends</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stage</span><span class="o">.</span><span class="n">get_bwd_send_ops</span><span class="p">(</span><span class="n">bwd_mb_index</span><span class="p">)</span>
            <span class="n">send_work</span> <span class="o">=</span> <span class="n">_batch_p2p</span><span class="p">(</span><span class="n">bwd_sends</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;bwd_send&quot;</span><span class="p">)</span>
            <span class="n">bwd_mb_index</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="c1"># Wait for the last backward send to finish</span>
        <span class="k">if</span> <span class="n">send_work</span><span class="p">:</span>
            <span class="n">send_work</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>

        <span class="c1"># Return losses if there is a container passed in</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_update_losses</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_stage</span><span class="p">,</span> <span class="n">losses</span><span class="p">)</span></div>


<span class="k">def</span> <span class="nf">_add_unshard_reshard</span><span class="p">(</span>
    <span class="n">compute_actions</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Optional</span><span class="p">[</span><span class="n">_Action</span><span class="p">]],</span>
    <span class="n">max_active_stages</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Optional</span><span class="p">[</span><span class="n">_Action</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Given a basic schedule involving only compute actions (F,B,W), add UNSHARD/RESHARD actions for FSDP.</span>

<span class="sd">    UNSHARD refers to fetching the full contents of an FSDP-sharded layer, requiring an all-gather operation.</span>
<span class="sd">    RESHARD does the opposite, releasing memory (but doing no commmunication)</span>

<span class="sd">    We abandon the &quot;timestep lock&quot;  during lowering</span>

<span class="sd">    max_active_stages controls how many prefetches we allow. It should be measured in mb and tuneable but in practice</span>
<span class="sd">    3 stages is probably the thing we want?</span>
<span class="sd">    (to account for having one f and one b active, and something else prefetching?)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">next_stage_indices</span><span class="p">(</span>
        <span class="n">count</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">next_actions</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Optional</span><span class="p">[</span><span class="n">_Action</span><span class="p">]]</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Remove duplicates (same stage, different microbatch), find next &#39;count&#39; stages that will do compute.&quot;&quot;&quot;</span>
        <span class="n">seen</span><span class="p">:</span> <span class="n">Set</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
        <span class="n">ret</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">next_actions</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">a</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">a</span><span class="o">.</span><span class="n">stage_index</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">seen</span><span class="p">:</span>
                <span class="n">seen</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">stage_index</span><span class="p">)</span>
                <span class="n">ret</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">stage_index</span><span class="p">)</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">ret</span><span class="p">)</span> <span class="o">==</span> <span class="n">count</span><span class="p">:</span>
                    <span class="k">break</span>
        <span class="k">return</span> <span class="n">ret</span>

    <span class="n">active_stages</span><span class="p">:</span> <span class="n">Set</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
    <span class="n">fsdp_aware_actions</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Optional</span><span class="p">[</span><span class="n">_Action</span><span class="p">]]</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">def</span> <span class="nf">_unshard</span><span class="p">(</span><span class="n">stage_index</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
        <span class="n">active_stages</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">stage_index</span><span class="p">)</span>
        <span class="n">fsdp_aware_actions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">_Action</span><span class="p">(</span><span class="n">stage_index</span><span class="p">,</span> <span class="n">UNSHARD</span><span class="p">,</span> <span class="kc">None</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">_reshard</span><span class="p">(</span><span class="n">stage_index</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
        <span class="n">active_stages</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">stage_index</span><span class="p">)</span>
        <span class="n">fsdp_aware_actions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">_Action</span><span class="p">(</span><span class="n">stage_index</span><span class="p">,</span> <span class="n">RESHARD</span><span class="p">,</span> <span class="kc">None</span><span class="p">))</span>

    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">action</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">compute_actions</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">action</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">continue</span>

        <span class="c1"># We prefetch the next N stages we&#39;ll see, dropping existing stages to make room</span>
        <span class="n">next_n</span> <span class="o">=</span> <span class="n">next_stage_indices</span><span class="p">(</span><span class="n">max_active_stages</span><span class="p">,</span> <span class="n">compute_actions</span><span class="p">[</span><span class="n">i</span><span class="p">:])</span>
        <span class="c1"># Fetch needs to be ordered correctly, so don&#39;t use a set</span>
        <span class="n">fetch</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">s</span><span class="p">:</span> <span class="n">s</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">active_stages</span><span class="p">,</span> <span class="n">next_n</span><span class="p">))</span>
        <span class="c1"># Unclear what the best policy is for eviction, but we can maintain order so we do</span>
        <span class="n">evict</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">s</span><span class="p">:</span> <span class="n">s</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">next_n</span><span class="p">,</span> <span class="n">active_stages</span><span class="p">))</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
            <span class="s2">&quot;_add_unshard_reshard Step </span><span class="si">%d</span><span class="s2"> active: </span><span class="si">%s</span><span class="s2"> fetch </span><span class="si">%s</span><span class="s2">, evict </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span>
            <span class="n">i</span><span class="p">,</span>
            <span class="n">active_stages</span><span class="p">,</span>
            <span class="n">fetch</span><span class="p">,</span>
            <span class="n">evict</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">for</span> <span class="n">stage</span> <span class="ow">in</span> <span class="n">evict</span><span class="p">:</span>
            <span class="n">_reshard</span><span class="p">(</span><span class="n">stage</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">stage</span> <span class="ow">in</span> <span class="n">fetch</span><span class="p">:</span>
            <span class="n">_unshard</span><span class="p">(</span><span class="n">stage</span><span class="p">)</span>
        <span class="n">fsdp_aware_actions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">fsdp_aware_actions</span>


<span class="k">def</span> <span class="nf">_add_send_recv</span><span class="p">(</span>
    <span class="n">compute_actions</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Optional</span><span class="p">[</span><span class="n">_Action</span><span class="p">]]],</span>
    <span class="n">stage_to_rank</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="nb">int</span><span class="p">],</span> <span class="nb">int</span><span class="p">],</span>
    <span class="n">num_stages</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">_Action</span><span class="p">]]:</span>
    <span class="n">comm_actions</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">_Action</span><span class="p">]]</span> <span class="o">=</span> <span class="p">{</span><span class="n">rank</span><span class="p">:</span> <span class="p">[]</span> <span class="k">for</span> <span class="n">rank</span> <span class="ow">in</span> <span class="n">compute_actions</span><span class="p">}</span>

    <span class="k">def</span> <span class="nf">_has_comms</span><span class="p">(</span><span class="n">action</span><span class="p">:</span> <span class="n">_Action</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">action</span><span class="o">.</span><span class="n">computation_type</span> <span class="o">==</span> <span class="n">F</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">action</span><span class="o">.</span><span class="n">stage_index</span> <span class="o">!=</span> <span class="n">num_stages</span> <span class="o">-</span> <span class="mi">1</span>
        <span class="k">elif</span> <span class="n">action</span><span class="o">.</span><span class="n">computation_type</span> <span class="o">==</span> <span class="n">B</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">action</span><span class="o">.</span><span class="n">stage_index</span> <span class="o">!=</span> <span class="mi">0</span>
        <span class="k">return</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="nf">_get_comms</span><span class="p">(</span><span class="n">action</span><span class="p">:</span> <span class="n">_Action</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">_Action</span><span class="p">,</span> <span class="n">_Action</span><span class="p">]:</span>
        <span class="k">assert</span> <span class="n">_has_comms</span><span class="p">(</span><span class="n">action</span><span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">action</span><span class="si">}</span><span class="s2"> is not a valid comm action&quot;</span>
        <span class="n">stage_idx</span> <span class="o">=</span> <span class="n">action</span><span class="o">.</span><span class="n">stage_index</span>
        <span class="n">ctype</span> <span class="o">=</span> <span class="n">action</span><span class="o">.</span><span class="n">computation_type</span>
        <span class="n">mb_idx</span> <span class="o">=</span> <span class="n">action</span><span class="o">.</span><span class="n">microbatch_index</span>
        <span class="n">send</span> <span class="o">=</span> <span class="n">_Action</span><span class="p">(</span><span class="n">stage_idx</span><span class="p">,</span> <span class="n">SEND_F</span> <span class="k">if</span> <span class="n">ctype</span> <span class="o">==</span> <span class="n">F</span> <span class="k">else</span> <span class="n">SEND_B</span><span class="p">,</span> <span class="n">mb_idx</span><span class="p">)</span>
        <span class="n">recv_stage_idx</span> <span class="o">=</span> <span class="n">stage_idx</span> <span class="o">+</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">ctype</span> <span class="o">==</span> <span class="n">F</span> <span class="k">else</span> <span class="n">stage_idx</span> <span class="o">-</span> <span class="mi">1</span>
        <span class="n">recv</span> <span class="o">=</span> <span class="n">_Action</span><span class="p">(</span><span class="n">recv_stage_idx</span><span class="p">,</span> <span class="n">RECV_F</span> <span class="k">if</span> <span class="n">ctype</span> <span class="o">==</span> <span class="n">F</span> <span class="k">else</span> <span class="n">RECV_B</span><span class="p">,</span> <span class="n">mb_idx</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">send</span><span class="p">,</span> <span class="n">recv</span>

    <span class="k">def</span> <span class="nf">_ready_to_schedule</span><span class="p">(</span>
        <span class="n">action</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">_Action</span><span class="p">],</span> <span class="n">prev_actions</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">_Action</span><span class="p">]</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;We don&#39;t put our own recv ops in the schedule, we let a sender on another rank put our recv ops in place.</span>
<span class="sd">        This helps ensure a sane (non-hanging) ordering of sends and recvs.</span>
<span class="sd">        But it also means we might not be able to schedule our next compute action yet.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">action</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">True</span>
        <span class="k">elif</span> <span class="n">action</span><span class="o">.</span><span class="n">computation_type</span> <span class="o">==</span> <span class="n">F</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">action</span><span class="o">.</span><span class="n">stage_index</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">expected_recv</span> <span class="o">=</span> <span class="n">_Action</span><span class="p">(</span>
                <span class="n">action</span><span class="o">.</span><span class="n">stage_index</span><span class="p">,</span>
                <span class="n">RECV_F</span> <span class="k">if</span> <span class="n">action</span><span class="o">.</span><span class="n">computation_type</span> <span class="o">==</span> <span class="n">F</span> <span class="k">else</span> <span class="n">RECV_B</span><span class="p">,</span>
                <span class="n">action</span><span class="o">.</span><span class="n">microbatch_index</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">return</span> <span class="n">expected_recv</span> <span class="ow">in</span> <span class="n">prev_actions</span>
        <span class="k">elif</span> <span class="n">action</span><span class="o">.</span><span class="n">computation_type</span> <span class="o">==</span> <span class="n">B</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">action</span><span class="o">.</span><span class="n">stage_index</span> <span class="o">==</span> <span class="n">num_stages</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">expected_recv</span> <span class="o">=</span> <span class="n">_Action</span><span class="p">(</span>
                <span class="n">action</span><span class="o">.</span><span class="n">stage_index</span><span class="p">,</span>
                <span class="n">RECV_F</span> <span class="k">if</span> <span class="n">action</span><span class="o">.</span><span class="n">computation_type</span> <span class="o">==</span> <span class="n">F</span> <span class="k">else</span> <span class="n">RECV_B</span><span class="p">,</span>
                <span class="n">action</span><span class="o">.</span><span class="n">microbatch_index</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">return</span> <span class="n">expected_recv</span> <span class="ow">in</span> <span class="n">prev_actions</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">True</span>

    <span class="k">while</span> <span class="n">compute_actions</span><span class="p">:</span>
        <span class="n">progress</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="c1"># go in order of ranks even if dict keys aren&#39;t ordered</span>
        <span class="k">for</span> <span class="n">rank</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">compute_actions</span><span class="p">)):</span>
            <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">compute_actions</span><span class="p">[</span><span class="n">rank</span><span class="p">])</span> <span class="o">&gt;</span> <span class="mi">0</span>
            <span class="n">action</span> <span class="o">=</span> <span class="n">compute_actions</span><span class="p">[</span><span class="n">rank</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>

            <span class="k">if</span> <span class="ow">not</span> <span class="n">_ready_to_schedule</span><span class="p">(</span><span class="n">action</span><span class="p">,</span> <span class="n">comm_actions</span><span class="p">[</span><span class="n">rank</span><span class="p">]):</span>
                <span class="k">continue</span>

            <span class="k">if</span> <span class="n">action</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">comm_actions</span><span class="p">[</span><span class="n">rank</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">_has_comms</span><span class="p">(</span><span class="n">action</span><span class="p">):</span>
                    <span class="n">send</span><span class="p">,</span> <span class="n">recv</span> <span class="o">=</span> <span class="n">_get_comms</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
                    <span class="c1"># TODO we can avoid send/recv if the 2 stages are on the same rank.</span>
                    <span class="c1"># should we avoid that in the runtime or here?</span>
                    <span class="n">comm_actions</span><span class="p">[</span><span class="n">rank</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">send</span><span class="p">)</span>
                    <span class="n">comm_actions</span><span class="p">[</span><span class="n">stage_to_rank</span><span class="p">(</span><span class="n">recv</span><span class="o">.</span><span class="n">stage_index</span><span class="p">)]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">recv</span><span class="p">)</span>

            <span class="n">compute_actions</span><span class="p">[</span><span class="n">rank</span><span class="p">]</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">compute_actions</span><span class="p">[</span><span class="n">rank</span><span class="p">])</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">del</span> <span class="n">compute_actions</span><span class="p">[</span><span class="n">rank</span><span class="p">]</span>
            <span class="n">progress</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">assert</span> <span class="n">progress</span><span class="p">,</span> <span class="s2">&quot;Malformed compute schedule, can&#39;t schedule sends/recvs&quot;</span>
    <span class="k">return</span> <span class="n">comm_actions</span>


<div class="viewcode-block" id="PipelineScheduleMulti"><a class="viewcode-back" href="../../../../distributed.pipelining.html#torch.distributed.pipelining.schedules.PipelineScheduleMulti">[docs]</a><span class="k">class</span> <span class="nc">PipelineScheduleMulti</span><span class="p">(</span><span class="n">_PipelineSchedule</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Base class for multi-stage schedules.</span>
<span class="sd">    Implements the `step` method.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">stages</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">_PipelineStageBase</span><span class="p">],</span>
        <span class="n">n_microbatches</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">loss_fn</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">args_chunk_spec</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">TensorChunkSpec</span><span class="p">,</span> <span class="o">...</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">kwargs_chunk_spec</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">TensorChunkSpec</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">output_merge_spec</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Any</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">stage_index_to_group_rank</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">use_full_backward</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">stages</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Multi-stage schedule expects at least two stages but got </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">stages</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
        <span class="c1"># Init parent</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">n_microbatches</span><span class="o">=</span><span class="n">n_microbatches</span><span class="p">,</span>
            <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss_fn</span><span class="p">,</span>
            <span class="n">args_chunk_spec</span><span class="o">=</span><span class="n">args_chunk_spec</span><span class="p">,</span>
            <span class="n">kwargs_chunk_spec</span><span class="o">=</span><span class="n">kwargs_chunk_spec</span><span class="p">,</span>
            <span class="n">output_merge_spec</span><span class="o">=</span><span class="n">output_merge_spec</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="c1"># Self attributes</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_stages</span> <span class="o">=</span> <span class="n">stages</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_num_stages</span> <span class="o">=</span> <span class="n">stages</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">num_stages</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pp_group_size</span> <span class="o">=</span> <span class="n">stages</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">group_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rank</span> <span class="o">=</span> <span class="n">stages</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">group_rank</span>
        <span class="c1"># Set the pipeline stage states</span>
        <span class="k">if</span> <span class="n">stage_index_to_group_rank</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">stage</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stages</span><span class="p">:</span>
                <span class="n">stage</span><span class="o">.</span><span class="n">stage_index_to_group_rank</span> <span class="o">=</span> <span class="n">stage_index_to_group_rank</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stage_index_to_group_rank</span> <span class="o">=</span> <span class="n">stages</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">stage_index_to_group_rank</span>

        <span class="c1"># Set the same has_backward flag for stage object</span>
        <span class="k">for</span> <span class="n">stage</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stages</span><span class="p">:</span>
            <span class="n">stage</span><span class="o">.</span><span class="n">has_backward</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_has_backward</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_should_compute_loss</span> <span class="o">=</span> <span class="p">(</span>
            <span class="k">lambda</span> <span class="n">stage</span><span class="p">:</span> <span class="n">stage</span><span class="o">.</span><span class="n">is_last</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">_loss_fn</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="p">)</span>

        <span class="c1"># This will be set during init of derived schedules</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pipeline_order</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Optional</span><span class="p">[</span><span class="n">_Action</span><span class="p">]]]</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">use_full_backward</span> <span class="o">=</span> <span class="n">use_full_backward</span>

        <span class="c1"># TODO: later replace this with lazy shape inference during forward</span>
        <span class="c1"># Prepare forward send/recv infrastructure for stage</span>
        <span class="k">for</span> <span class="n">stage</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stages</span><span class="p">:</span>
            <span class="n">stage</span><span class="o">.</span><span class="n">_prepare_forward_infra</span><span class="p">(</span><span class="n">n_microbatches</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_has_backward</span><span class="p">:</span>
                <span class="n">stage</span><span class="o">.</span><span class="n">_prepare_backward_infra</span><span class="p">(</span><span class="n">n_microbatches</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_dump_csv</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">filename</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Dump a CSV representation of the schedule into a file with the provided filename.</span>
<span class="sd">        This API will most likely get renamed/refactored so is marked as internal for now.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">,</span> <span class="n">newline</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">csvfile</span><span class="p">:</span>
            <span class="n">writer</span> <span class="o">=</span> <span class="n">csv</span><span class="o">.</span><span class="n">writer</span><span class="p">(</span><span class="n">csvfile</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">rank</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">pipeline_order</span><span class="p">:</span>
                <span class="n">writer</span><span class="o">.</span><span class="n">writerow</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pipeline_order</span><span class="p">[</span><span class="n">rank</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">_validate_schedule</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># TODO(whc) this should be merged with the logic in test_schedule.py#L453-L554</span>
        <span class="k">def</span> <span class="nf">_validate_rank_actions</span><span class="p">(</span>
            <span class="n">actions</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">_Action</span> <span class="o">|</span> <span class="kc">None</span><span class="p">]],</span>
            <span class="n">num_stages</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
            <span class="n">num_microbatches</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="p">):</span>
            <span class="c1"># We will count all the actions per stage and ensure they happen in a valid order</span>
            <span class="c1"># (e.g. F before B before W for a given microbatch)</span>
            <span class="n">stage_actions</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="n">_ComputationType</span><span class="p">,</span> <span class="n">Set</span><span class="p">]]</span> <span class="o">=</span> <span class="p">{</span>
                <span class="n">stage_id</span><span class="p">:</span> <span class="p">{</span>
                    <span class="n">F</span><span class="p">:</span> <span class="nb">set</span><span class="p">(),</span>
                    <span class="n">B</span><span class="p">:</span> <span class="nb">set</span><span class="p">(),</span>
                    <span class="n">W</span><span class="p">:</span> <span class="nb">set</span><span class="p">(),</span>
                <span class="p">}</span>
                <span class="k">for</span> <span class="n">stage_id</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_stages</span><span class="p">)</span>
            <span class="p">}</span>
            <span class="k">for</span> <span class="n">rank</span> <span class="ow">in</span> <span class="n">actions</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">action</span> <span class="ow">in</span> <span class="n">actions</span><span class="p">[</span><span class="n">rank</span><span class="p">]:</span>
                    <span class="k">if</span> <span class="n">action</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="k">continue</span>
                    <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span>
                        <span class="n">action</span><span class="p">,</span> <span class="n">_Action</span>
                    <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Got an invalid action: </span><span class="si">{</span><span class="n">action</span><span class="si">}</span><span class="s2">, expected instance of _Action&quot;</span>
                    <span class="n">s_id</span> <span class="o">=</span> <span class="n">action</span><span class="o">.</span><span class="n">stage_index</span>
                    <span class="n">ctype</span> <span class="o">=</span> <span class="n">action</span><span class="o">.</span><span class="n">computation_type</span>
                    <span class="n">mb_id</span> <span class="o">=</span> <span class="n">action</span><span class="o">.</span><span class="n">microbatch_index</span>
                    <span class="k">if</span> <span class="n">ctype</span> <span class="o">==</span> <span class="n">F</span><span class="p">:</span>
                        <span class="n">stage_actions</span><span class="p">[</span><span class="n">s_id</span><span class="p">][</span><span class="n">F</span><span class="p">]</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">mb_id</span><span class="p">)</span>
                    <span class="k">elif</span> <span class="n">ctype</span> <span class="o">==</span> <span class="n">B</span><span class="p">:</span>
                        <span class="k">assert</span> <span class="p">(</span>
                            <span class="n">mb_id</span> <span class="ow">in</span> <span class="n">stage_actions</span><span class="p">[</span><span class="n">s_id</span><span class="p">][</span><span class="n">F</span><span class="p">]</span>
                        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Running Backward for stage </span><span class="si">{</span><span class="n">s_id</span><span class="si">}</span><span class="s2">, microbatch </span><span class="si">{</span><span class="n">mb_id</span><span class="si">}</span><span class="s2"> without first running Forward&quot;</span>
                        <span class="n">stage_actions</span><span class="p">[</span><span class="n">s_id</span><span class="p">][</span><span class="n">B</span><span class="p">]</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">mb_id</span><span class="p">)</span>
                    <span class="k">elif</span> <span class="n">ctype</span> <span class="o">==</span> <span class="n">W</span><span class="p">:</span>
                        <span class="k">assert</span> <span class="p">(</span>
                            <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_full_backward</span>
                        <span class="p">),</span> <span class="s2">&quot;Schedule contains &#39;W&#39; actions, but is configured to use full backward&quot;</span>
                        <span class="k">assert</span> <span class="p">(</span>
                            <span class="n">mb_id</span> <span class="ow">in</span> <span class="n">stage_actions</span><span class="p">[</span><span class="n">s_id</span><span class="p">][</span><span class="n">B</span><span class="p">]</span>
                        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Running Weight for stage </span><span class="si">{</span><span class="n">s_id</span><span class="si">}</span><span class="s2">, microbatch </span><span class="si">{</span><span class="n">mb_id</span><span class="si">}</span><span class="s2"> without first running Backward&quot;</span>
                        <span class="n">stage_actions</span><span class="p">[</span><span class="n">s_id</span><span class="p">][</span><span class="n">W</span><span class="p">]</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">mb_id</span><span class="p">)</span>

            <span class="k">for</span> <span class="n">s_id</span> <span class="ow">in</span> <span class="n">stage_actions</span><span class="p">:</span>
                <span class="k">for</span> <span class="n">ctype</span> <span class="ow">in</span> <span class="p">(</span><span class="n">F</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">W</span><span class="p">):</span>
                    <span class="n">stage_mb</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">stage_actions</span><span class="p">[</span><span class="n">s_id</span><span class="p">][</span><span class="n">ctype</span><span class="p">])</span>
                    <span class="k">assert</span> <span class="p">(</span>
                        <span class="n">stage_mb</span> <span class="o">==</span> <span class="n">num_microbatches</span>
                    <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Got </span><span class="si">{</span><span class="n">stage_mb</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">ctype</span><span class="si">}</span><span class="s2"> microbatches for stage </span><span class="si">{</span><span class="n">s_id</span><span class="si">}</span><span class="s2">, expected </span><span class="si">{</span><span class="n">num_microbatches</span><span class="si">}</span><span class="s2">&quot;</span>

        <span class="k">assert</span> <span class="p">(</span>
            <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pipeline_order</span><span class="p">)</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">pp_group_size</span>
        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Schedule has incorrect number of ranks - expected </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">pp_group_size</span><span class="si">}</span><span class="s2">, actual </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pipeline_order</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">for</span> <span class="n">rank</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pp_group_size</span><span class="p">):</span>
            <span class="k">assert</span> <span class="p">(</span>
                <span class="n">rank</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">pipeline_order</span>
            <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Schedule is missing actions for rank </span><span class="si">{</span><span class="n">rank</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="n">_validate_rank_actions</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">pipeline_order</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_num_stages</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_n_microbatches</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_load_csv</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">filename</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Load a CSV representation of the schedule from a file with the provided filename.</span>
<span class="sd">        This API will most likely get renamed/refactored so is marked as internal for now.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">newline</span><span class="o">=</span><span class="s2">&quot;&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">csvfile</span><span class="p">:</span>
            <span class="n">reader</span> <span class="o">=</span> <span class="n">csv</span><span class="o">.</span><span class="n">reader</span><span class="p">(</span><span class="n">csvfile</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">rank</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">reader</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">pipeline_order</span><span class="p">[</span><span class="n">rank</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">_Action</span><span class="o">.</span><span class="n">from_str</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">row</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_validate_schedule</span><span class="p">()</span>

<div class="viewcode-block" id="PipelineScheduleMulti.step"><a class="viewcode-back" href="../../../../distributed.pipelining.html#torch.distributed.pipelining.schedules.PipelineScheduleMulti.step">[docs]</a>    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">losses</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Run one iteration of the pipeline schedule with *whole-batch* input.</span>
<span class="sd">        Will chunk the input into microbatches automatically, and go through the</span>
<span class="sd">        microbatches according to the schedule implementation.</span>

<span class="sd">        args: positional arguments to the model (as in non-pipeline case).</span>
<span class="sd">        kwargs: keyword arguments to the model (as in non-pipeline case).</span>
<span class="sd">        target: target for the loss function.</span>
<span class="sd">        losses: a list to store the losses for each microbatch.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># Clean per iteration</span>
        <span class="k">for</span> <span class="n">stage</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stages</span><span class="p">:</span>
            <span class="n">stage</span><span class="o">.</span><span class="n">clear_runtime_states</span><span class="p">()</span>

        <span class="c1"># Split inputs into microbatches</span>
        <span class="n">args_split</span><span class="p">,</span> <span class="n">kwargs_split</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_split_inputs</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">)</span>

        <span class="c1"># Split target into microbatches</span>
        <span class="k">if</span> <span class="n">target</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">targets_split</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor_split</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_n_microbatches</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">targets_split</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># Run microbatches</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_step_microbatches</span><span class="p">(</span><span class="n">args_split</span><span class="p">,</span> <span class="n">kwargs_split</span><span class="p">,</span> <span class="n">targets_split</span><span class="p">,</span> <span class="n">losses</span><span class="p">)</span>

        <span class="c1"># Return merged results per original format</span>
        <span class="k">for</span> <span class="n">stage</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stages</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">stage</span><span class="o">.</span><span class="n">is_last</span><span class="p">:</span>
                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_merge_outputs</span><span class="p">(</span><span class="n">stage</span><span class="o">.</span><span class="n">output_chunks</span><span class="p">)</span>
        <span class="c1"># Does not contain the last stage</span>
        <span class="k">return</span> <span class="kc">None</span></div>

    <span class="k">def</span> <span class="nf">_step_microbatches</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">arg_mbs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">kwarg_mbs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">target_mbs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">losses</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Operate on the microbatches for looped schedules (multiple stages on each rank).</span>

<span class="sd">        TODO: Does not use sorted_batch_isend_irecv(). As a result, this schedule does</span>
<span class="sd">        not support models with skip connections.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">arg_mbs</span><span class="p">,</span> <span class="n">kwarg_mbs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_check_inputs</span><span class="p">(</span><span class="n">arg_mbs</span><span class="p">,</span> <span class="n">kwarg_mbs</span><span class="p">,</span> <span class="n">target_mbs</span><span class="p">,</span> <span class="n">losses</span><span class="p">)</span>

        <span class="c1"># Based on the plan in Step 1 created in __init__:</span>
        <span class="c1"># 2. Perform communication based on the pipeline_order</span>
        <span class="n">stage_index_to_stage</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">_PipelineStageBase</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
            <span class="n">stage</span><span class="o">.</span><span class="n">stage_index</span><span class="p">:</span> <span class="n">stage</span> <span class="k">for</span> <span class="n">stage</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stages</span>
        <span class="p">}</span>

        <span class="c1"># determine prev_rank and next_rank based on which ranks are next to</span>
        <span class="c1"># the stages in the pipeline_order</span>
        <span class="n">all_prev_ranks</span><span class="p">:</span> <span class="n">Set</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
        <span class="n">all_next_ranks</span><span class="p">:</span> <span class="n">Set</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">stage_index</span> <span class="ow">in</span> <span class="n">stage_index_to_stage</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="c1"># TODO: assumption that stages only communicate from distances of +1/-1 (no skip connections)</span>
            <span class="k">if</span> <span class="n">stage_index</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">all_prev_ranks</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">stage_index_to_group_rank</span><span class="p">[</span><span class="n">stage_index</span> <span class="o">-</span> <span class="mi">1</span><span class="p">])</span>
            <span class="k">if</span> <span class="n">stage_index</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_stages</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">all_next_ranks</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">stage_index_to_group_rank</span><span class="p">[</span><span class="n">stage_index</span> <span class="o">+</span> <span class="mi">1</span><span class="p">])</span>

        <span class="k">for</span> <span class="n">time_step</span><span class="p">,</span> <span class="n">action</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pipeline_order</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">rank</span><span class="p">]):</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">ops</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">dist</span><span class="o">.</span><span class="n">P2POp</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="k">if</span> <span class="n">action</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">computation_type</span> <span class="o">=</span> <span class="n">action</span><span class="o">.</span><span class="n">computation_type</span>
                    <span class="n">mb_index</span> <span class="o">=</span> <span class="n">action</span><span class="o">.</span><span class="n">microbatch_index</span>
                    <span class="n">stage_index</span> <span class="o">=</span> <span class="n">action</span><span class="o">.</span><span class="n">stage_index</span>
                    <span class="k">assert</span> <span class="p">(</span>
                        <span class="n">mb_index</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                    <span class="p">),</span> <span class="s2">&quot;All currently supported action types require valid microbatch_index&quot;</span>
                    <span class="k">if</span> <span class="n">computation_type</span> <span class="o">==</span> <span class="n">_ComputationType</span><span class="o">.</span><span class="n">FORWARD</span><span class="p">:</span>
                        <span class="c1"># perform forward computation</span>
                        <span class="n">stage</span> <span class="o">=</span> <span class="n">stage_index_to_stage</span><span class="p">[</span><span class="n">stage_index</span><span class="p">]</span>
                        <span class="n">output</span> <span class="o">=</span> <span class="n">stage</span><span class="o">.</span><span class="n">forward_one_chunk</span><span class="p">(</span>
                            <span class="n">mb_index</span><span class="p">,</span> <span class="n">arg_mbs</span><span class="p">[</span><span class="n">mb_index</span><span class="p">],</span> <span class="n">kwarg_mbs</span><span class="p">[</span><span class="n">mb_index</span><span class="p">]</span>
                        <span class="p">)</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">_maybe_compute_loss</span><span class="p">(</span><span class="n">stage</span><span class="p">,</span> <span class="n">output</span><span class="p">,</span> <span class="n">target_mbs</span><span class="p">,</span> <span class="n">mb_index</span><span class="p">)</span>
                        <span class="n">ops</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">stage</span><span class="o">.</span><span class="n">get_fwd_send_ops</span><span class="p">(</span><span class="n">mb_index</span><span class="p">))</span>
                    <span class="k">elif</span> <span class="n">computation_type</span> <span class="o">==</span> <span class="n">_ComputationType</span><span class="o">.</span><span class="n">BACKWARD</span><span class="p">:</span>
                        <span class="c1"># perform backward computation</span>
                        <span class="n">stage</span> <span class="o">=</span> <span class="n">stage_index_to_stage</span><span class="p">[</span><span class="n">stage_index</span><span class="p">]</span>
                        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_maybe_get_loss</span><span class="p">(</span><span class="n">stage</span><span class="p">,</span> <span class="n">mb_index</span><span class="p">)</span>
                        <span class="n">stage</span><span class="o">.</span><span class="n">backward_one_chunk</span><span class="p">(</span>
                            <span class="n">mb_index</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span> <span class="n">full_backward</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">use_full_backward</span>
                        <span class="p">)</span>
                        <span class="n">ops</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">stage</span><span class="o">.</span><span class="n">get_bwd_send_ops</span><span class="p">(</span><span class="n">mb_index</span><span class="p">))</span>
                    <span class="k">elif</span> <span class="n">computation_type</span> <span class="o">==</span> <span class="n">_ComputationType</span><span class="o">.</span><span class="n">WEIGHT</span><span class="p">:</span>
                        <span class="c1"># perform weight update</span>
                        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_full_backward</span><span class="p">:</span>
                            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                                <span class="sa">f</span><span class="s2">&quot;We detected a weight update in the pipeline schedule, but </span><span class="se">\</span>
<span class="s2">                                </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">use_full_backward</span><span class="si">=}</span><span class="s2">&quot;</span>
                            <span class="p">)</span>
                        <span class="n">stage</span> <span class="o">=</span> <span class="n">stage_index_to_stage</span><span class="p">[</span><span class="n">stage_index</span><span class="p">]</span>
                        <span class="n">stage</span><span class="o">.</span><span class="n">backward_weight_one_chunk</span><span class="p">(</span><span class="n">mb_index</span><span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unknown computation type </span><span class="si">{</span><span class="n">computation_type</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

                <span class="c1"># Look at the neighboring ranks for this current timestep and determine whether</span>
                <span class="c1"># this current rank needs to do any recv communication</span>
                <span class="k">for</span> <span class="n">prev_rank</span> <span class="ow">in</span> <span class="n">all_prev_ranks</span><span class="p">:</span>
                    <span class="n">prev_rank_ops</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pipeline_order</span><span class="p">[</span><span class="n">prev_rank</span><span class="p">]</span>
                    <span class="n">prev_rank_action</span> <span class="o">=</span> <span class="kc">None</span>
                    <span class="k">if</span> <span class="n">time_step</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">prev_rank_ops</span><span class="p">):</span>
                        <span class="n">prev_rank_action</span> <span class="o">=</span> <span class="n">prev_rank_ops</span><span class="p">[</span><span class="n">time_step</span><span class="p">]</span>
                    <span class="k">if</span> <span class="n">prev_rank_action</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="n">computation_type</span> <span class="o">=</span> <span class="n">prev_rank_action</span><span class="o">.</span><span class="n">computation_type</span>
                        <span class="n">mb_index</span> <span class="o">=</span> <span class="n">prev_rank_action</span><span class="o">.</span><span class="n">microbatch_index</span>
                        <span class="n">stage_index</span> <span class="o">=</span> <span class="n">prev_rank_action</span><span class="o">.</span><span class="n">stage_index</span>
                        <span class="k">assert</span> <span class="p">(</span>
                            <span class="n">mb_index</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                        <span class="p">),</span> <span class="s2">&quot;All currently supported action types require valid microbatch_index&quot;</span>
                        <span class="c1"># Only handle sends for the forward from a previous rank</span>
                        <span class="k">if</span> <span class="n">computation_type</span> <span class="o">==</span> <span class="n">_ComputationType</span><span class="o">.</span><span class="n">FORWARD</span><span class="p">:</span>
                            <span class="c1"># If not the last stage, then receive fwd activations</span>
                            <span class="k">if</span> <span class="n">stage_index</span> <span class="o">+</span> <span class="mi">1</span> <span class="ow">in</span> <span class="n">stage_index_to_stage</span><span class="p">:</span>
                                <span class="c1"># TODO: We are assuming that stage will always receive from stage-1</span>
                                <span class="c1"># however that is not necessarily true of get_fwd_recv_ops</span>
                                <span class="n">stage</span> <span class="o">=</span> <span class="n">stage_index_to_stage</span><span class="p">[</span><span class="n">stage_index</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>
                                <span class="n">ops</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">stage</span><span class="o">.</span><span class="n">get_fwd_recv_ops</span><span class="p">(</span><span class="n">mb_index</span><span class="p">))</span>
                        <span class="k">elif</span> <span class="p">(</span>
                            <span class="n">computation_type</span> <span class="o">==</span> <span class="n">_ComputationType</span><span class="o">.</span><span class="n">BACKWARD</span>
                            <span class="ow">or</span> <span class="n">computation_type</span> <span class="o">==</span> <span class="n">_ComputationType</span><span class="o">.</span><span class="n">WEIGHT</span>
                        <span class="p">):</span>
                            <span class="c1"># Previous rank doing backward or weight update has no influence for the current rank forward recv</span>
                            <span class="k">pass</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                                <span class="sa">f</span><span class="s2">&quot;Unknown computation type </span><span class="si">{</span><span class="n">computation_type</span><span class="si">}</span><span class="s2">&quot;</span>
                            <span class="p">)</span>
                <span class="k">for</span> <span class="n">next_rank</span> <span class="ow">in</span> <span class="n">all_next_ranks</span><span class="p">:</span>
                    <span class="n">next_rank_ops</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pipeline_order</span><span class="p">[</span><span class="n">next_rank</span><span class="p">]</span>
                    <span class="n">next_rank_action</span> <span class="o">=</span> <span class="kc">None</span>
                    <span class="k">if</span> <span class="n">time_step</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">next_rank_ops</span><span class="p">):</span>
                        <span class="n">next_rank_action</span> <span class="o">=</span> <span class="n">next_rank_ops</span><span class="p">[</span><span class="n">time_step</span><span class="p">]</span>
                    <span class="k">if</span> <span class="n">next_rank_action</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                        <span class="n">computation_type</span> <span class="o">=</span> <span class="n">next_rank_action</span><span class="o">.</span><span class="n">computation_type</span>
                        <span class="n">mb_index</span> <span class="o">=</span> <span class="n">next_rank_action</span><span class="o">.</span><span class="n">microbatch_index</span>
                        <span class="n">stage_index</span> <span class="o">=</span> <span class="n">next_rank_action</span><span class="o">.</span><span class="n">stage_index</span>
                        <span class="k">assert</span> <span class="p">(</span>
                            <span class="n">mb_index</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                        <span class="p">),</span> <span class="s2">&quot;All currently supported action types require valid microbatch_index&quot;</span>
                        <span class="c1"># Only handle receives for the backwards from a next rank</span>
                        <span class="k">if</span> <span class="p">(</span>
                            <span class="n">computation_type</span> <span class="o">==</span> <span class="n">_ComputationType</span><span class="o">.</span><span class="n">FORWARD</span>
                            <span class="ow">or</span> <span class="n">computation_type</span> <span class="o">==</span> <span class="n">_ComputationType</span><span class="o">.</span><span class="n">WEIGHT</span>
                        <span class="p">):</span>
                            <span class="c1"># Next rank doing forward or weight update has no influence for the current rank backward recv</span>
                            <span class="k">pass</span>
                        <span class="k">elif</span> <span class="n">computation_type</span> <span class="o">==</span> <span class="n">_ComputationType</span><span class="o">.</span><span class="n">BACKWARD</span><span class="p">:</span>
                            <span class="c1"># If not the first stage, then receive bwd gradients</span>
                            <span class="k">if</span> <span class="n">stage_index</span> <span class="o">-</span> <span class="mi">1</span> <span class="ow">in</span> <span class="n">stage_index_to_stage</span><span class="p">:</span>
                                <span class="c1"># TODO: We are assuming that stage will always receive from stage+1</span>
                                <span class="c1"># however that is not necessarily true of get_bwd_recv_ops</span>
                                <span class="n">stage</span> <span class="o">=</span> <span class="n">stage_index_to_stage</span><span class="p">[</span><span class="n">stage_index</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>
                                <span class="n">ops</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">stage</span><span class="o">.</span><span class="n">get_bwd_recv_ops</span><span class="p">(</span><span class="n">mb_index</span><span class="p">))</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                                <span class="sa">f</span><span class="s2">&quot;Unknown computation type </span><span class="si">{</span><span class="n">computation_type</span><span class="si">}</span><span class="s2">&quot;</span>
                            <span class="p">)</span>

                <span class="c1"># do the communication</span>
                <span class="k">if</span> <span class="n">ops</span><span class="p">:</span>
                    <span class="n">_batch_p2p</span><span class="p">(</span><span class="n">ops</span><span class="p">)</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>
            <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span>
                    <span class="s2">&quot;[Rank </span><span class="si">%s</span><span class="s2">] pipeline schedule </span><span class="si">%s</span><span class="s2"> caught the following exception </span><span class="se">\</span>
<span class="s2">                     at time_step </span><span class="si">%s</span><span class="s2"> when running action </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">rank</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span>
                    <span class="n">time_step</span><span class="p">,</span>
                    <span class="n">action</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">_format_pipeline_order</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pipeline_order</span><span class="p">))</span>
                <span class="k">raise</span> <span class="n">e</span>
        <span class="c1"># Return losses if there is a container passed in</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_update_losses</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_stages</span><span class="p">,</span> <span class="n">losses</span><span class="p">)</span></div>


<div class="viewcode-block" id="ScheduleLoopedBFS"><a class="viewcode-back" href="../../../../distributed.pipelining.html#torch.distributed.pipelining.schedules.ScheduleLoopedBFS">[docs]</a><span class="k">class</span> <span class="nc">ScheduleLoopedBFS</span><span class="p">(</span><span class="n">PipelineScheduleMulti</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Breadth-First Pipeline Parallelism.</span>
<span class="sd">    See https://arxiv.org/abs/2211.05953 for details.</span>
<span class="sd">    Simliar to Interleaved 1F1B, Looped BFS supports multiple stages per rank.</span>
<span class="sd">    What is different is that when microbatches are ready for multiple local</span>
<span class="sd">    stages, Loops BFS will prioritizes the earlier stage, running all available</span>
<span class="sd">    microbatches at once.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">stages</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">_PipelineStageBase</span><span class="p">],</span>
        <span class="n">n_microbatches</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">loss_fn</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">output_merge_spec</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Any</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">stages</span><span class="o">=</span><span class="n">stages</span><span class="p">,</span>
            <span class="n">n_microbatches</span><span class="o">=</span><span class="n">n_microbatches</span><span class="p">,</span>
            <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss_fn</span><span class="p">,</span>
            <span class="n">output_merge_spec</span><span class="o">=</span><span class="n">output_merge_spec</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># 1. Create the pipeline_order (all ranks do this calculation)</span>
        <span class="c1"># This will be used to keep track of the current state of the entire pipeline</span>
        <span class="c1"># pipeline_order[rank] = [Action(computation_type, microbatch_index, stage_index), ...]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pipeline_order</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Optional</span><span class="p">[</span><span class="n">_Action</span><span class="p">]]]</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="c1"># ========================================================================</span>
        <span class="k">for</span> <span class="n">rank</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pp_group_size</span><span class="p">):</span>
            <span class="n">rank_ops</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_calculate_single_rank_operations</span><span class="p">(</span><span class="n">rank</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">pipeline_order</span><span class="p">[</span><span class="n">rank</span><span class="p">]</span> <span class="o">=</span> <span class="n">rank_ops</span>

    <span class="k">def</span> <span class="nf">_calculate_single_rank_operations</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rank</span><span class="p">):</span>
        <span class="n">n_local_stages</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_stages</span><span class="p">)</span>
        <span class="n">stage_indices</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span>
            <span class="n">rank</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">pp_group_size</span> <span class="o">*</span> <span class="n">n_local_stages</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">pp_group_size</span>
        <span class="p">)</span>

        <span class="c1"># Store the list of operations used for that rank</span>
        <span class="n">rank_ops</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Optional</span><span class="p">[</span><span class="n">_Action</span><span class="p">]]</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="c1"># Pre-padding, rank starts with no-ops based on the warmup.</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">rank</span><span class="p">):</span>
            <span class="n">rank_ops</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">stage_index</span> <span class="ow">in</span> <span class="n">stage_indices</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">mb_index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_n_microbatches</span><span class="p">):</span>
                <span class="n">rank_ops</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                    <span class="n">_Action</span><span class="p">(</span><span class="n">stage_index</span><span class="p">,</span> <span class="n">_ComputationType</span><span class="o">.</span><span class="n">FORWARD</span><span class="p">,</span> <span class="n">mb_index</span><span class="p">)</span>
                <span class="p">)</span>

        <span class="c1"># wait for the first backward to trickle up</span>
        <span class="c1"># which is 2 for every hop away</span>
        <span class="n">post_warmup_ops</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pp_group_size</span> <span class="o">-</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">rank</span><span class="p">)</span>
        <span class="n">rank_ops</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">post_warmup_ops</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">stage_index</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="n">stage_indices</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">mb_index</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_n_microbatches</span><span class="p">)):</span>
                <span class="n">rank_ops</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                    <span class="n">_Action</span><span class="p">(</span><span class="n">stage_index</span><span class="p">,</span> <span class="n">_ComputationType</span><span class="o">.</span><span class="n">BACKWARD</span><span class="p">,</span> <span class="n">mb_index</span><span class="p">)</span>
                <span class="p">)</span>
        <span class="k">return</span> <span class="n">rank_ops</span></div>


<span class="k">def</span> <span class="nf">_get_1f1b_rank_ops</span><span class="p">(</span>
    <span class="n">n_local_stages</span><span class="p">,</span>
    <span class="n">pp_group_size</span><span class="p">,</span>
    <span class="n">warmup_ops</span><span class="p">,</span>
    <span class="n">fwd_bwd_ops</span><span class="p">,</span>
    <span class="n">cooldown_ops</span><span class="p">,</span>
    <span class="n">rank</span><span class="p">,</span>
    <span class="n">forward_stage_index</span><span class="p">,</span>
    <span class="n">backward_stage_index</span><span class="p">,</span>
    <span class="n">num_1f1b_microbatches</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">enable_zero_bubble</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">):</span>
    <span class="c1"># All stages start with handling microbatch 0</span>
    <span class="n">fwd_stage_mb_index</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
    <span class="n">bwd_stage_mb_index</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
    <span class="n">weight_stage_mb_index</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="n">defaultdict</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>

    <span class="c1"># Store the list of operations used for that rank</span>
    <span class="n">rank_ops</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Optional</span><span class="p">[</span><span class="n">_Action</span><span class="p">]]</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="c1"># Pre-padding, rank starts with no-ops based on the warmup.</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">rank</span><span class="p">):</span>
        <span class="n">rank_ops</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
    <span class="c1"># These are used to calculate the number of slots to fill with no-ops, to account for the delay in warmup</span>
    <span class="c1"># when we want to wait for the backward to trickle back up and start 1f1b to align all ranks.</span>
    <span class="c1"># Formula:</span>
    <span class="c1"># pre-padding + warmup_ops + post_warmup_ops = earliest time step of first backward</span>
    <span class="c1"># post_warmup_ops = [earliest time step of first backward] - (warmup_ops + pre-padding)</span>
    <span class="c1"># earliest time step of first backward = [local_stages * group_size + 2 * (group_size - 1 - rank)]</span>
    <span class="c1"># warmup_ops = calculated above</span>
    <span class="n">post_warmup_ops</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">n_local_stages</span> <span class="o">*</span> <span class="n">pp_group_size</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">pp_group_size</span> <span class="o">-</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">rank</span><span class="p">)</span>
    <span class="p">)</span> <span class="o">-</span> <span class="p">(</span><span class="n">warmup_ops</span> <span class="o">+</span> <span class="n">rank</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">enable_zero_bubble</span><span class="p">:</span>
        <span class="n">post_warmup_ops</span> <span class="o">=</span> <span class="n">pp_group_size</span> <span class="o">-</span> <span class="n">rank</span> <span class="o">-</span> <span class="mi">1</span>

    <span class="n">total_ops</span> <span class="o">=</span> <span class="n">warmup_ops</span> <span class="o">+</span> <span class="n">fwd_bwd_ops</span> <span class="o">+</span> <span class="n">cooldown_ops</span>

    <span class="n">backward_op_ids</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">weight_op_count</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">for</span> <span class="n">op</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">total_ops</span><span class="p">):</span>
        <span class="c1"># Warmup phase</span>
        <span class="k">if</span> <span class="n">op</span> <span class="o">&lt;</span> <span class="n">warmup_ops</span><span class="p">:</span>
            <span class="n">fwd_stage_index</span> <span class="o">=</span> <span class="n">forward_stage_index</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>
            <span class="c1"># This will assign the current microbatch index and update it as well</span>
            <span class="n">fwd_stage_mb_index</span><span class="p">[</span><span class="n">fwd_stage_index</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">mb_index</span> <span class="o">:=</span> <span class="n">fwd_stage_mb_index</span><span class="p">[</span><span class="n">fwd_stage_index</span><span class="p">]</span>
            <span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
            <span class="n">rank_ops</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">_Action</span><span class="p">(</span><span class="n">fwd_stage_index</span><span class="p">,</span> <span class="n">_ComputationType</span><span class="o">.</span><span class="n">FORWARD</span><span class="p">,</span> <span class="n">mb_index</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="n">op</span> <span class="o">==</span> <span class="n">warmup_ops</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
                <span class="c1"># This is the last step in the warmup phase, so we need to wait for the backward to trickle back up</span>
                <span class="n">rank_ops</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">post_warmup_ops</span><span class="p">)</span>
        <span class="c1"># 1F1B Phase (forward and backward)</span>
        <span class="k">elif</span> <span class="n">warmup_ops</span> <span class="o">&lt;=</span> <span class="n">op</span> <span class="o">&lt;</span> <span class="n">warmup_ops</span> <span class="o">+</span> <span class="n">fwd_bwd_ops</span><span class="p">:</span>
            <span class="n">fwd_stage_index</span> <span class="o">=</span> <span class="n">forward_stage_index</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>
            <span class="n">fwd_stage_mb_index</span><span class="p">[</span><span class="n">fwd_stage_index</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">fwd_mb_index</span> <span class="o">:=</span> <span class="n">fwd_stage_mb_index</span><span class="p">[</span><span class="n">fwd_stage_index</span><span class="p">]</span>
            <span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
            <span class="n">rank_ops</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">_Action</span><span class="p">(</span><span class="n">fwd_stage_index</span><span class="p">,</span> <span class="n">_ComputationType</span><span class="o">.</span><span class="n">FORWARD</span><span class="p">,</span> <span class="n">fwd_mb_index</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="n">bwd_stage_index</span> <span class="o">=</span> <span class="n">backward_stage_index</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>
            <span class="n">bwd_stage_mb_index</span><span class="p">[</span><span class="n">bwd_stage_index</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">bwd_mb_index</span> <span class="o">:=</span> <span class="n">bwd_stage_mb_index</span><span class="p">[</span><span class="n">bwd_stage_index</span><span class="p">]</span>
            <span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
            <span class="n">rank_ops</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">_Action</span><span class="p">(</span><span class="n">bwd_stage_index</span><span class="p">,</span> <span class="n">_ComputationType</span><span class="o">.</span><span class="n">BACKWARD</span><span class="p">,</span> <span class="n">bwd_mb_index</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="n">backward_op_ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">enable_zero_bubble</span> <span class="ow">and</span> <span class="n">op</span> <span class="o">-</span> <span class="n">warmup_ops</span> <span class="o">&gt;=</span> <span class="n">num_1f1b_microbatches</span><span class="p">:</span>
                <span class="n">weight_stage_index</span> <span class="o">=</span> <span class="n">backward_stage_index</span><span class="p">(</span>
                    <span class="n">backward_op_ids</span><span class="p">[</span><span class="n">weight_op_count</span><span class="p">]</span>
                <span class="p">)</span>
                <span class="n">weight_stage_mb_index</span><span class="p">[</span><span class="n">weight_stage_index</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="n">weight_mb_index</span> <span class="o">:=</span> <span class="n">weight_stage_mb_index</span><span class="p">[</span><span class="n">weight_stage_index</span><span class="p">]</span>
                <span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
                <span class="n">rank_ops</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                    <span class="n">_Action</span><span class="p">(</span>
                        <span class="n">weight_stage_index</span><span class="p">,</span> <span class="n">_ComputationType</span><span class="o">.</span><span class="n">WEIGHT</span><span class="p">,</span> <span class="n">weight_mb_index</span>
                    <span class="p">)</span>
                <span class="p">)</span>
                <span class="n">weight_op_count</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="c1"># Cooldown phase</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># During cooldown phase, we need steps to align with 1f1b happening in other ranks</span>
            <span class="c1"># TODO: we don&#39;t need to always append, after all 1f1b are finished we can stop appending None</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">enable_zero_bubble</span><span class="p">:</span>
                <span class="n">rank_ops</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>

            <span class="n">bwd_stage_index</span> <span class="o">=</span> <span class="n">backward_stage_index</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>
            <span class="n">bwd_stage_mb_index</span><span class="p">[</span><span class="n">bwd_stage_index</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">bwd_mb_index</span> <span class="o">:=</span> <span class="n">bwd_stage_mb_index</span><span class="p">[</span><span class="n">bwd_stage_index</span><span class="p">]</span>
            <span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
            <span class="n">rank_ops</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">_Action</span><span class="p">(</span><span class="n">bwd_stage_index</span><span class="p">,</span> <span class="n">_ComputationType</span><span class="o">.</span><span class="n">BACKWARD</span><span class="p">,</span> <span class="n">bwd_mb_index</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="n">backward_op_ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">op</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">enable_zero_bubble</span> <span class="ow">and</span> <span class="n">op</span> <span class="o">-</span> <span class="n">warmup_ops</span> <span class="o">&gt;=</span> <span class="n">num_1f1b_microbatches</span><span class="p">:</span>
                <span class="n">weight_stage_index</span> <span class="o">=</span> <span class="n">backward_stage_index</span><span class="p">(</span>
                    <span class="n">backward_op_ids</span><span class="p">[</span><span class="n">weight_op_count</span><span class="p">]</span>
                <span class="p">)</span>
                <span class="n">weight_stage_mb_index</span><span class="p">[</span><span class="n">weight_stage_index</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="n">weight_mb_index</span> <span class="o">:=</span> <span class="n">weight_stage_mb_index</span><span class="p">[</span><span class="n">weight_stage_index</span><span class="p">]</span>
                <span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
                <span class="n">rank_ops</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                    <span class="n">_Action</span><span class="p">(</span>
                        <span class="n">weight_stage_index</span><span class="p">,</span> <span class="n">_ComputationType</span><span class="o">.</span><span class="n">WEIGHT</span><span class="p">,</span> <span class="n">weight_mb_index</span>
                    <span class="p">)</span>
                <span class="p">)</span>
                <span class="n">weight_op_count</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="k">while</span> <span class="n">enable_zero_bubble</span> <span class="ow">and</span> <span class="n">weight_op_count</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">backward_op_ids</span><span class="p">):</span>
        <span class="n">weight_stage_index</span> <span class="o">=</span> <span class="n">backward_stage_index</span><span class="p">(</span><span class="n">backward_op_ids</span><span class="p">[</span><span class="n">weight_op_count</span><span class="p">])</span>
        <span class="n">weight_stage_mb_index</span><span class="p">[</span><span class="n">weight_stage_index</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">weight_mb_index</span> <span class="o">:=</span> <span class="n">weight_stage_mb_index</span><span class="p">[</span><span class="n">weight_stage_index</span><span class="p">]</span>
        <span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="n">rank_ops</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">_Action</span><span class="p">(</span><span class="n">weight_stage_index</span><span class="p">,</span> <span class="n">_ComputationType</span><span class="o">.</span><span class="n">WEIGHT</span><span class="p">,</span> <span class="n">weight_mb_index</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">weight_op_count</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="k">return</span> <span class="n">rank_ops</span>


<div class="viewcode-block" id="ScheduleInterleaved1F1B"><a class="viewcode-back" href="../../../../distributed.pipelining.html#torch.distributed.pipelining.schedules.ScheduleInterleaved1F1B">[docs]</a><span class="k">class</span> <span class="nc">ScheduleInterleaved1F1B</span><span class="p">(</span><span class="n">PipelineScheduleMulti</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The Interleaved 1F1B schedule.</span>
<span class="sd">    See https://arxiv.org/pdf/2104.04473 for details.</span>
<span class="sd">    Will perform one forward and one backward on the microbatches in steady</span>
<span class="sd">    state and supports multiple stages per rank. When microbatches are ready for</span>
<span class="sd">    multiple local stages, Interleaved 1F1B prioritizes the earlier microbatch</span>
<span class="sd">    (also called &quot;depth first&quot;).</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">stages</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">_PipelineStageBase</span><span class="p">],</span>
        <span class="n">n_microbatches</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">loss_fn</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">args_chunk_spec</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">TensorChunkSpec</span><span class="p">,</span> <span class="o">...</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">kwargs_chunk_spec</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">TensorChunkSpec</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">output_merge_spec</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Any</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pp_group_size</span> <span class="o">=</span> <span class="n">stages</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">group_size</span>
        <span class="c1"># TODO: is this limitation a must?</span>
        <span class="k">if</span> <span class="n">n_microbatches</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">pp_group_size</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Interleaved 1F1B schedule requires the number of microbatches (</span><span class="si">{</span><span class="n">n_microbatches</span><span class="si">}</span><span class="s2">) </span><span class="se">\</span>
<span class="s2">                to be a multiple of the number of pipeline ranks (</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">pp_group_size</span><span class="si">}</span><span class="s2">).&quot;</span>
            <span class="p">)</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">stages</span><span class="o">=</span><span class="n">stages</span><span class="p">,</span>
            <span class="n">n_microbatches</span><span class="o">=</span><span class="n">n_microbatches</span><span class="p">,</span>
            <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss_fn</span><span class="p">,</span>
            <span class="n">args_chunk_spec</span><span class="o">=</span><span class="n">args_chunk_spec</span><span class="p">,</span>
            <span class="n">kwargs_chunk_spec</span><span class="o">=</span><span class="n">kwargs_chunk_spec</span><span class="p">,</span>
            <span class="n">output_merge_spec</span><span class="o">=</span><span class="n">output_merge_spec</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">n_local_stages</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">stages</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rank</span> <span class="o">=</span> <span class="n">stages</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">group_rank</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">group</span> <span class="o">=</span> <span class="n">stages</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">group</span>

        <span class="c1"># 1. Create the pipeline_order (all ranks do this calculation)</span>
        <span class="c1"># This will be used to keep track of the current state of the entire pipeline</span>
        <span class="c1"># pipeline_order[rank] = [Action(computation_type, microbatch_index, stage_index), ...]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pipeline_order</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Optional</span><span class="p">[</span><span class="n">_Action</span><span class="p">]]]</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="k">for</span> <span class="n">rank</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pp_group_size</span><span class="p">):</span>
            <span class="n">rank_ops</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_calculate_single_rank_operations</span><span class="p">(</span><span class="n">rank</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">pipeline_order</span><span class="p">[</span><span class="n">rank</span><span class="p">]</span> <span class="o">=</span> <span class="n">rank_ops</span>

    <span class="k">def</span> <span class="nf">_calculate_single_rank_operations</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rank</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Optional</span><span class="p">[</span><span class="n">_Action</span><span class="p">]]:</span>
        <span class="k">def</span> <span class="nf">get_rank_warmup_ops</span><span class="p">(</span><span class="n">rank</span><span class="p">):</span>
            <span class="c1"># Warms up operations for last stage</span>
            <span class="n">warmups_ops_last_stage</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_local_stages</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">pp_group_size</span>
            <span class="c1"># Increment warmup operations by 2 for each hop away from the last stage</span>
            <span class="n">warmup_ops</span> <span class="o">=</span> <span class="n">warmups_ops_last_stage</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">pp_group_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="n">rank</span><span class="p">)</span>
            <span class="c1"># We cannot have more warmup operations than there are number of microbatches, so cap it there</span>
            <span class="k">return</span> <span class="nb">min</span><span class="p">(</span><span class="n">warmup_ops</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_n_microbatches</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_local_stages</span><span class="p">)</span>

        <span class="n">warmup_ops</span> <span class="o">=</span> <span class="n">get_rank_warmup_ops</span><span class="p">(</span><span class="n">rank</span><span class="p">)</span>
        <span class="n">microbatch_ops</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_local_stages</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">_n_microbatches</span>
        <span class="c1"># fwd_bwd_ops should encompass the remaining forwards</span>
        <span class="n">fwd_bwd_ops</span> <span class="o">=</span> <span class="n">microbatch_ops</span> <span class="o">-</span> <span class="n">warmup_ops</span>
        <span class="c1"># cooldown_ops should encompass the remaining backwards</span>
        <span class="n">cooldown_ops</span> <span class="o">=</span> <span class="n">microbatch_ops</span> <span class="o">-</span> <span class="n">fwd_bwd_ops</span>
        <span class="c1"># total ops encompass both forward and backward ops</span>
        <span class="n">total_ops</span> <span class="o">=</span> <span class="n">warmup_ops</span> <span class="o">+</span> <span class="n">fwd_bwd_ops</span> <span class="o">+</span> <span class="n">cooldown_ops</span>
        <span class="c1"># warmup_ops + fwd_bwd_ops * 2 + cooldown_ops == microbatch_ops * 2</span>

        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
            <span class="s2">&quot;rank </span><span class="si">%s</span><span class="s2">, warmup_ops </span><span class="si">%s</span><span class="s2">, 1f1b </span><span class="si">%s</span><span class="s2">, cooldown_ops </span><span class="si">%s</span><span class="s2"> total_ops </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span>
            <span class="n">rank</span><span class="p">,</span>
            <span class="n">warmup_ops</span><span class="p">,</span>
            <span class="n">fwd_bwd_ops</span><span class="p">,</span>
            <span class="n">cooldown_ops</span><span class="p">,</span>
            <span class="n">total_ops</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># Calculates the stage index based on step and pp_group_size</span>
        <span class="k">def</span> <span class="nf">forward_stage_index</span><span class="p">(</span><span class="n">step</span><span class="p">):</span>
            <span class="c1"># Get the local index from 0 to n_local_stages-1</span>
            <span class="n">local_index</span> <span class="o">=</span> <span class="p">(</span><span class="n">step</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">pp_group_size</span><span class="p">)</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_local_stages</span>
            <span class="k">return</span> <span class="p">(</span><span class="n">local_index</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">pp_group_size</span><span class="p">)</span> <span class="o">+</span> <span class="n">rank</span>

        <span class="k">def</span> <span class="nf">backward_stage_index</span><span class="p">(</span><span class="n">step</span><span class="p">):</span>
            <span class="n">local_index</span> <span class="o">=</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">n_local_stages</span>
                <span class="o">-</span> <span class="mi">1</span>
                <span class="o">-</span> <span class="p">((</span><span class="n">step</span> <span class="o">-</span> <span class="n">warmup_ops</span><span class="p">)</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">pp_group_size</span><span class="p">)</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_local_stages</span>
            <span class="p">)</span>
            <span class="k">return</span> <span class="p">(</span><span class="n">local_index</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">pp_group_size</span><span class="p">)</span> <span class="o">+</span> <span class="n">rank</span>

        <span class="k">return</span> <span class="n">_get_1f1b_rank_ops</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n_local_stages</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">pp_group_size</span><span class="p">,</span>
            <span class="n">warmup_ops</span><span class="p">,</span>
            <span class="n">fwd_bwd_ops</span><span class="p">,</span>
            <span class="n">cooldown_ops</span><span class="p">,</span>
            <span class="n">rank</span><span class="p">,</span>
            <span class="n">forward_stage_index</span><span class="p">,</span>
            <span class="n">backward_stage_index</span><span class="p">,</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="ScheduleFlexibleInterleaved1F1B"><a class="viewcode-back" href="../../../../distributed.pipelining.html#torch.distributed.pipelining.schedules.ScheduleFlexibleInterleaved1F1B">[docs]</a><span class="k">class</span> <span class="nc">ScheduleFlexibleInterleaved1F1B</span><span class="p">(</span><span class="n">PipelineScheduleMulti</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The Flexible Interleaved 1F1B schedule.</span>

<span class="sd">    This schedule is mostly similar to the interleaved 1F1B schedule.</span>
<span class="sd">    It differs by being relaxing the requirement of num_microbatch % pp_size == 0.</span>
<span class="sd">    Using the flex_pp schedule, we will have num_rounds = max(1, n_microbatches // pp_group_size) and</span>
<span class="sd">    it works as long as n_microbatches % num_rounds is 0. As a few examples, support</span>

<span class="sd">    1. pp_group_size = 4, n_microbatches = 10. We will have num_rounds = 2 and n_microbatches % 2 is 0.</span>
<span class="sd">    2. pp_group_size = 4, n_microbatches = 3. We will have num_rounds = 1 and n_microbatches % 1 is 0.</span>

<span class="sd">    When enable_zero_bubble is True, we will use the ZB1P schedule in https://openreview.net/pdf?id=tuzTN0eIO5</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">stages</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">_PipelineStageBase</span><span class="p">],</span>
        <span class="n">n_microbatches</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">loss_fn</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">args_chunk_spec</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">TensorChunkSpec</span><span class="p">,</span> <span class="o">...</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">kwargs_chunk_spec</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">TensorChunkSpec</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">output_merge_spec</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Any</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">enable_zero_bubble</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pp_group_size</span> <span class="o">=</span> <span class="n">stages</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">group_size</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">stages</span><span class="o">=</span><span class="n">stages</span><span class="p">,</span>
            <span class="n">n_microbatches</span><span class="o">=</span><span class="n">n_microbatches</span><span class="p">,</span>
            <span class="n">loss_fn</span><span class="o">=</span><span class="n">loss_fn</span><span class="p">,</span>
            <span class="n">args_chunk_spec</span><span class="o">=</span><span class="n">args_chunk_spec</span><span class="p">,</span>
            <span class="n">kwargs_chunk_spec</span><span class="o">=</span><span class="n">kwargs_chunk_spec</span><span class="p">,</span>
            <span class="n">output_merge_spec</span><span class="o">=</span><span class="n">output_merge_spec</span><span class="p">,</span>
            <span class="n">use_full_backward</span><span class="o">=</span><span class="ow">not</span> <span class="n">enable_zero_bubble</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_local_stages</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">stages</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rank</span> <span class="o">=</span> <span class="n">stages</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">group_rank</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">number_of_rounds</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_microbatches</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">pp_group_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">microbatches_per_round</span> <span class="o">=</span> <span class="n">n_microbatches</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">number_of_rounds</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">enable_zero_bubble</span> <span class="o">=</span> <span class="n">enable_zero_bubble</span>
        <span class="k">if</span> <span class="n">n_microbatches</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">number_of_rounds</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Flexible Interleaved 1F1B requires the number of microbatches to be a &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;multiple of the number of rounds (</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">number_of_rounds</span><span class="si">}</span><span class="s2">), &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;but got </span><span class="si">{</span><span class="n">n_microbatches</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>
        <span class="c1"># 1. Create the pipeline_order (all ranks do this calculation)</span>
        <span class="c1"># This will be used to keep track of the current state of the entire pipeline</span>
        <span class="c1"># pipeline_order[rank] = [Action(computation_type, microbatch_index, stage_index), ...]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pipeline_order</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Optional</span><span class="p">[</span><span class="n">_Action</span><span class="p">]]]</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">rank</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pp_group_size</span><span class="p">):</span>
            <span class="n">rank_ops</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_calculate_single_rank_operations</span><span class="p">(</span><span class="n">rank</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">pipeline_order</span><span class="p">[</span><span class="n">rank</span><span class="p">]</span> <span class="o">=</span> <span class="n">rank_ops</span>

        <span class="c1"># This function add bubbles to the generated schedule based on dependencies of actions</span>
        <span class="c1"># Note that the ZB1P schedule will not require bubbles to be manually added and it is</span>
        <span class="c1"># only useful when n_microbatches &lt;= microbatches_per_round</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pipeline_order</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_bubbles_to_actions</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n_local_stages</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">pp_group_size</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_calculate_single_rank_operations</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rank</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Optional</span><span class="p">[</span><span class="n">_Action</span><span class="p">]]:</span>
        <span class="k">def</span> <span class="nf">get_rank_warmup_ops</span><span class="p">(</span><span class="n">rank</span><span class="p">):</span>
            <span class="c1"># Warms up operations for last stage</span>
            <span class="n">warmups_ops_last_stage</span> <span class="o">=</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">n_local_stages</span> <span class="o">-</span> <span class="mi">1</span>
            <span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">microbatches_per_round</span>
            <span class="c1"># Increment warmup operations by 2 for each hop away from the last stage</span>
            <span class="n">multiply_factor</span> <span class="o">=</span> <span class="mi">1</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">enable_zero_bubble</span> <span class="k">else</span> <span class="mi">2</span>
            <span class="n">warmup_ops</span> <span class="o">=</span> <span class="n">warmups_ops_last_stage</span> <span class="o">+</span> <span class="n">multiply_factor</span> <span class="o">*</span> <span class="p">(</span>
                <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pp_group_size</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="n">rank</span>
            <span class="p">)</span>

            <span class="c1"># We cannot have more warmup operations than there are number of microbatches, so cap it there</span>
            <span class="k">return</span> <span class="nb">min</span><span class="p">(</span><span class="n">warmup_ops</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_n_microbatches</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_local_stages</span><span class="p">)</span>

        <span class="n">warmup_ops</span> <span class="o">=</span> <span class="n">get_rank_warmup_ops</span><span class="p">(</span><span class="n">rank</span><span class="p">)</span>
        <span class="n">microbatch_ops</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_local_stages</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">_n_microbatches</span>
        <span class="c1"># fwd_bwd_ops should encompass the remaining forwards</span>
        <span class="n">fwd_bwd_ops</span> <span class="o">=</span> <span class="n">microbatch_ops</span> <span class="o">-</span> <span class="n">warmup_ops</span>
        <span class="c1"># cooldown_ops should encompass the remaining backwards</span>
        <span class="n">cooldown_ops</span> <span class="o">=</span> <span class="n">microbatch_ops</span> <span class="o">-</span> <span class="n">fwd_bwd_ops</span>
        <span class="c1"># total ops encompass both forward and backward ops</span>
        <span class="n">total_ops</span> <span class="o">=</span> <span class="n">warmup_ops</span> <span class="o">+</span> <span class="n">fwd_bwd_ops</span> <span class="o">+</span> <span class="n">cooldown_ops</span>
        <span class="c1"># warmup_ops + fwd_bwd_ops * 2 + cooldown_ops == microbatch_ops * 2</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
            <span class="s2">&quot;rank </span><span class="si">%s</span><span class="s2">, warmup_ops </span><span class="si">%s</span><span class="s2">, 1f1b </span><span class="si">%s</span><span class="s2">, cooldown_ops </span><span class="si">%s</span><span class="s2"> total_ops </span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span>
            <span class="n">rank</span><span class="p">,</span>
            <span class="n">warmup_ops</span><span class="p">,</span>
            <span class="n">fwd_bwd_ops</span><span class="p">,</span>
            <span class="n">cooldown_ops</span><span class="p">,</span>
            <span class="n">total_ops</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># Calculates the stage index based on step and pp_group_size</span>

        <span class="k">def</span> <span class="nf">forward_stage_index</span><span class="p">(</span><span class="n">step</span><span class="p">):</span>
            <span class="c1"># Get the local index from 0 to n_local_stages-1</span>
            <span class="n">local_index</span> <span class="o">=</span> <span class="p">(</span><span class="n">step</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">microbatches_per_round</span><span class="p">)</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_local_stages</span>
            <span class="k">return</span> <span class="p">(</span><span class="n">local_index</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">pp_group_size</span><span class="p">)</span> <span class="o">+</span> <span class="n">rank</span>

        <span class="k">def</span> <span class="nf">backward_stage_index</span><span class="p">(</span><span class="n">step</span><span class="p">):</span>
            <span class="n">local_index</span> <span class="o">=</span> <span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">n_local_stages</span>
                <span class="o">-</span> <span class="mi">1</span>
                <span class="o">-</span> <span class="p">((</span><span class="n">step</span> <span class="o">-</span> <span class="n">warmup_ops</span><span class="p">)</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">microbatches_per_round</span><span class="p">)</span>
                <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_local_stages</span>
            <span class="p">)</span>
            <span class="k">return</span> <span class="p">(</span><span class="n">local_index</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">pp_group_size</span><span class="p">)</span> <span class="o">+</span> <span class="n">rank</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">enable_zero_bubble</span><span class="p">:</span>
            <span class="n">num_1f1b_microbatches</span> <span class="o">=</span> <span class="n">rank</span>

            <span class="k">return</span> <span class="n">_get_1f1b_rank_ops</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">n_local_stages</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">pp_group_size</span><span class="p">,</span>
                <span class="n">warmup_ops</span><span class="p">,</span>
                <span class="n">fwd_bwd_ops</span><span class="p">,</span>
                <span class="n">cooldown_ops</span><span class="p">,</span>
                <span class="n">rank</span><span class="p">,</span>
                <span class="n">forward_stage_index</span><span class="p">,</span>
                <span class="n">backward_stage_index</span><span class="p">,</span>
                <span class="n">num_1f1b_microbatches</span><span class="p">,</span>
                <span class="n">enable_zero_bubble</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="k">return</span> <span class="n">_get_1f1b_rank_ops</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">n_local_stages</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">pp_group_size</span><span class="p">,</span>
            <span class="n">warmup_ops</span><span class="p">,</span>
            <span class="n">fwd_bwd_ops</span><span class="p">,</span>
            <span class="n">cooldown_ops</span><span class="p">,</span>
            <span class="n">rank</span><span class="p">,</span>
            <span class="n">forward_stage_index</span><span class="p">,</span>
            <span class="n">backward_stage_index</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_add_bubbles_to_actions</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_stages_global</span><span class="p">):</span>
        <span class="n">actions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pipeline_order</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">enable_zero_bubble</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">actions</span>

        <span class="k">def</span> <span class="nf">need_bubble</span><span class="p">(</span><span class="n">stage</span><span class="p">,</span> <span class="n">op</span><span class="p">,</span> <span class="n">microbatch</span><span class="p">,</span> <span class="n">num_stages_global</span><span class="p">,</span> <span class="n">seen_ops</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">op</span> <span class="o">==</span> <span class="n">_ComputationType</span><span class="o">.</span><span class="n">FORWARD</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">stage</span> <span class="o">!=</span> <span class="mi">0</span> <span class="ow">and</span> <span class="p">(</span><span class="n">stage</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">op</span><span class="p">,</span> <span class="n">microbatch</span><span class="p">)</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">seen_ops</span><span class="p">:</span>
                    <span class="k">return</span> <span class="kc">True</span>
            <span class="k">elif</span> <span class="n">op</span> <span class="o">==</span> <span class="n">_ComputationType</span><span class="o">.</span><span class="n">BACKWARD</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">stage</span> <span class="o">==</span> <span class="n">num_stages_global</span> <span class="o">-</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="k">return</span> <span class="p">(</span><span class="n">stage</span><span class="p">,</span> <span class="n">_ComputationType</span><span class="o">.</span><span class="n">FORWARD</span><span class="p">,</span> <span class="n">microbatch</span><span class="p">)</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">seen_ops</span>
                <span class="k">return</span> <span class="p">(</span><span class="n">stage</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">op</span><span class="p">,</span> <span class="n">microbatch</span><span class="p">)</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">seen_ops</span>
            <span class="k">return</span> <span class="kc">False</span>

        <span class="n">seen_ops</span><span class="p">:</span> <span class="n">Set</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">_ComputationType</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
        <span class="n">result</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Optional</span><span class="p">[</span><span class="n">_Action</span><span class="p">]]]</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">next_pointer</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">bubbles_added</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">total_bubbles_added</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">for</span> <span class="n">rank</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pp_group_size</span><span class="p">):</span>
            <span class="n">result</span><span class="p">[</span><span class="n">rank</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">next_pointer</span><span class="p">[</span><span class="n">rank</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">bubbles_added</span><span class="p">[</span><span class="n">rank</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
            <span class="n">should_stop</span> <span class="o">=</span> <span class="kc">True</span>

            <span class="n">temp_seen_ops</span><span class="p">:</span> <span class="n">Set</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">_ComputationType</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>

            <span class="k">for</span> <span class="n">rank</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pp_group_size</span><span class="p">):</span>
                <span class="n">timestamp</span> <span class="o">=</span> <span class="n">next_pointer</span><span class="p">[</span><span class="n">rank</span><span class="p">]</span>
                <span class="k">if</span> <span class="n">timestamp</span> <span class="o">&gt;=</span> <span class="nb">len</span><span class="p">(</span><span class="n">actions</span><span class="p">[</span><span class="n">rank</span><span class="p">]):</span>
                    <span class="k">continue</span>

                <span class="n">should_stop</span> <span class="o">=</span> <span class="kc">False</span>

                <span class="k">if</span> <span class="n">actions</span><span class="p">[</span><span class="n">rank</span><span class="p">][</span><span class="n">timestamp</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">temp_action</span> <span class="o">=</span> <span class="n">actions</span><span class="p">[</span><span class="n">rank</span><span class="p">][</span><span class="n">timestamp</span><span class="p">]</span>
                    <span class="k">assert</span> <span class="n">temp_action</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
                    <span class="n">stage_index</span><span class="p">,</span> <span class="n">op</span><span class="p">,</span> <span class="n">microbatch</span> <span class="o">=</span> <span class="n">temp_action</span>
                    <span class="k">if</span> <span class="ow">not</span> <span class="n">need_bubble</span><span class="p">(</span>
                        <span class="n">stage_index</span><span class="p">,</span> <span class="n">op</span><span class="p">,</span> <span class="n">microbatch</span><span class="p">,</span> <span class="n">num_stages_global</span><span class="p">,</span> <span class="n">seen_ops</span>
                    <span class="p">):</span>
                        <span class="n">result</span><span class="p">[</span><span class="n">rank</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">actions</span><span class="p">[</span><span class="n">rank</span><span class="p">][</span><span class="n">timestamp</span><span class="p">])</span>
                        <span class="k">if</span> <span class="n">microbatch</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                            <span class="n">temp_seen_ops</span><span class="o">.</span><span class="n">add</span><span class="p">((</span><span class="n">stage_index</span><span class="p">,</span> <span class="n">op</span><span class="p">,</span> <span class="n">microbatch</span><span class="p">))</span>
                        <span class="n">next_pointer</span><span class="p">[</span><span class="n">rank</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">result</span><span class="p">[</span><span class="n">rank</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>
                        <span class="n">bubbles_added</span><span class="p">[</span><span class="n">rank</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">next_pointer</span><span class="p">[</span><span class="n">rank</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
                    <span class="n">result</span><span class="p">[</span><span class="n">rank</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span>

            <span class="n">seen_ops</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">temp_seen_ops</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">should_stop</span><span class="p">:</span>
                <span class="k">break</span>

        <span class="k">if</span> <span class="n">total_bubbles_added</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="s2">&quot;Non zero bubbles added: total_bubbles_added=</span><span class="si">%s</span><span class="s2"> bubbles_added=</span><span class="si">%s</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="n">total_bubbles_added</span><span class="p">,</span>
                <span class="n">bubbles_added</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">result</span></div>


<span class="k">def</span> <span class="nf">get_schedule_class</span><span class="p">(</span><span class="n">schedule_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Maps a schedule name to its corresponding class object.</span>

<span class="sd">    Args:</span>
<span class="sd">        schedule_name (str): The name of the schedule.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">schedule_map</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;1F1B&quot;</span><span class="p">:</span> <span class="n">Schedule1F1B</span><span class="p">,</span>
        <span class="s2">&quot;Interleaved1F1B&quot;</span><span class="p">:</span> <span class="n">ScheduleInterleaved1F1B</span><span class="p">,</span>
        <span class="s2">&quot;GPipe&quot;</span><span class="p">:</span> <span class="n">ScheduleGPipe</span><span class="p">,</span>
        <span class="s2">&quot;FlexibleInterleaved1F1B&quot;</span><span class="p">:</span> <span class="n">ScheduleFlexibleInterleaved1F1B</span><span class="p">,</span>
        <span class="s2">&quot;LoopedBFS&quot;</span><span class="p">:</span> <span class="n">ScheduleLoopedBFS</span><span class="p">,</span>
        <span class="s2">&quot;PipelineScheduleSingle&quot;</span><span class="p">:</span> <span class="n">PipelineScheduleSingle</span><span class="p">,</span>
        <span class="s2">&quot;PipelineScheduleMulti&quot;</span><span class="p">:</span> <span class="n">PipelineScheduleMulti</span><span class="p">,</span>
    <span class="p">}</span>
    <span class="k">if</span> <span class="n">schedule_name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">schedule_map</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unknown schedule name: </span><span class="si">{</span><span class="n">schedule_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">schedule_map</span><span class="p">[</span><span class="n">schedule_name</span><span class="p">]</span>
</pre></div>

             </article>
             
            </div>
            <footer>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2023, PyTorch Contributors.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>
<script>

var match = window.location.href.match(/\/_[a-zA-Z0-9_]*.html|_dynamo/gi);
var url = window.location.href.lastIndexOf(match[match.length-1]);

if (url)
  {
    var div = '<div class="admonition note"><p class="admonition-title">Note</p><p><i class="fa fa-exclamation-circle" aria-hidden="true">&nbsp</i> This page describes an internal API which is not intended to be used outside of the PyTorch codebase and can be modified or removed without notice.</p></div>'
    document.getElementById("pytorch-article").insertAdjacentHTML('afterBegin', div)
  }
</script>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              
            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../../../../" src="../../../../_static/documentation_options.js"></script>
         <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js"></script>
         <script src="../../../../_static/jquery.js"></script>
         <script src="../../../../_static/underscore.js"></script>
         <script src="../../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
         <script src="../../../../_static/doctools.js"></script>
         <script src="../../../../_static/sphinx_highlight.js"></script>
         <script src="../../../../_static/clipboard.min.js"></script>
         <script src="../../../../_static/copybutton.js"></script>
     

  

  <script type="text/javascript" src="../../../../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../../../../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../../../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 
<script script type="text/javascript">
  var collapsedSections = ['Developer Notes', 'Language Bindings', 'Libraries', 'Community'];
</script>

<img height="1" width="1" style="border-style:none;" alt="" src="https://www.googleadservices.com/pagead/conversion/795629140/?label=txkmCPmdtosBENSssfsC&amp;guid=ON&amp;script=0"/>


  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
            <li><a href="https://pytorch.org/get-started">Get Started</a></li>
            <li><a href="https://pytorch.org/features">Features</a></li>
            <li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
            <li><a href="https://pytorch.org/blog/">Blog</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/resources">Resources</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">Brand Guidelines</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">Stay up to date</li>
            <li><a href="https://www.facebook.com/pytorch" target="_blank">Facebook</a></li>
            <li><a href="https://twitter.com/pytorch" target="_blank">Twitter</a></li>
            <li><a href="https://www.youtube.com/pytorch" target="_blank">YouTube</a></li>
            <li><a href="https://www.linkedin.com/company/pytorch" target="_blank">LinkedIn</a></li>
          </ul>  
          </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">PyTorch Podcasts</li>
            <li><a href="https://open.spotify.com/show/6UzHKeiy368jKfQMKKvJY5" target="_blank">Spotify</a></li>
            <li><a href="https://podcasts.apple.com/us/podcast/pytorch-developer-podcast/id1566080008" target="_blank">Apple</a></li>
            <li><a href="https://www.google.com/podcasts?feed=aHR0cHM6Ly9mZWVkcy5zaW1wbGVjYXN0LmNvbS9PQjVGa0lsOA%3D%3D" target="_blank">Google</a></li>
            <li><a href="https://music.amazon.com/podcasts/7a4e6f0e-26c2-49e9-a478-41bd244197d0/PyTorch-Developer-Podcast?" target="_blank">Amazon</a></li>
          </ul>
         </div>
        </div>
        
        <div class="privacy-policy">
          <ul>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/terms/" target="_blank">Terms</a></li>
            <li class="privacy-policy-links">|</li>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/privacy-policy/" target="_blank">Privacy</a></li>
          </ul>
        </div>
        <div class="copyright">
        <p>© Copyright The Linux Foundation. The PyTorch Foundation is a project of The Linux Foundation.
          For web site terms of use, trademark policy and other policies applicable to The PyTorch Foundation please see
          <a href="https://www.linuxfoundation.org/policies/">www.linuxfoundation.org/policies/</a>. The PyTorch Foundation supports the PyTorch open source
          project, which has been established as PyTorch Project a Series of LF Projects, LLC. For policies applicable to the PyTorch Project a Series of LF Projects, LLC,
          please see <a href="https://www.lfprojects.org/policies/">www.lfprojects.org/policies/</a>.</p>
      </div>
     </div>

  </footer>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../../../../_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
           <li class="resources-mobile-menu-title">
             <a>Learn</a>
           </li>
           <ul class="resources-mobile-menu-items">
             <li>
               <a href="https://pytorch.org/get-started">Get Started</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials">Tutorials</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials/beginner/basics/intro.html">Learn the Basics</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials/recipes/recipes_index.html">PyTorch Recipes</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials/beginner/introyt.html">Introduction to PyTorch - YouTube Series</a>
             </li>
           </ul>
           <li class="resources-mobile-menu-title">
             <a>Ecosystem</a>
           </li>
           <ul class="resources-mobile-menu-items">
             <li>
               <a href="https://pytorch.org/ecosystem">Tools</a>
             </li>
             <li>
               <a href="https://pytorch.org/#community-module">Community</a>
             </li>
             <li>
               <a href="https://discuss.pytorch.org/">Forums</a>
             </li>
             <li>
               <a href="https://pytorch.org/resources">Developer Resources</a>
             </li>
             <li>
               <a href="https://pytorch.org/ecosystem/contributor-awards-2023">Contributor Awards - 2023</a>
             </li>
           </ul>

           <li class="resources-mobile-menu-title">
             <a>Edge</a>
           </li>

           <ul class="resources-mobile-menu-items">
             <li>
               <a href="https://pytorch.org/edge">About PyTorch Edge</a>
             </li>
             
             <li>
               <a href="https://pytorch.org/executorch-overview">ExecuTorch</a>
             </li>
           </ul>

           <li class="resources-mobile-menu-title">
             <a>Docs</a>
           </li>

           <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/docs/stable/index.html">PyTorch</a>
            </li>

            <li>
              <a href="https://pytorch.org/pytorch-domains">PyTorch Domains</a>
            </li>
          </ul>

          <li class="resources-mobile-menu-title">
            <a>Blog & News</a>
          </li>
            
           <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/blog/">PyTorch Blog</a>
            </li>
            <li>
              <a href="https://pytorch.org/community-blog">Community Blog</a>
            </li>

            <li>
              <a href="https://pytorch.org/videos">Videos</a>
            </li>

            <li>
              <a href="https://pytorch.org/community-stories">Community Stories</a>
            </li>
            <li>
              <a href="https://pytorch.org/events">Events</a>
            </li>
          </ul>
          
          <li class="resources-mobile-menu-title">
            <a>About</a>
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/foundation">PyTorch Foundation</a>
            </li>
            <li>
              <a href="https://pytorch.org/governing-board">Governing Board</a>
            </li>
          </ul>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../../../../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>