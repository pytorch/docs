torch.escape-hatch
======================
assume_constant_result
^^^^^^^^^^^^^^^^^^^^^^

.. note::

    Tags: :doc:`torch.escape-hatch <torch.escape-hatch>`

    Support Level: SUPPORTED

Original source code:

.. code-block:: python

    # mypy: allow-untyped-defs
    import torch
    import torch._dynamo as torchdynamo
    
    
    class AssumeConstantResult(torch.nn.Module):
        """
        Applying `assume_constant_result` decorator to burn make non-tracable code as constant.
        """
    
        @torchdynamo.assume_constant_result
        def get_item(self, y):
            return y.int().item()
    
        def forward(self, x, y):
            return x[: self.get_item(y)]
    
    example_args = (torch.randn(3, 2), torch.tensor(4))
    tags = {"torch.escape-hatch"}
    model = AssumeConstantResult()
    

    torch.export.export(model, example_args)

Result:

.. code-block::

    ExportedProgram:
        class GraphModule(torch.nn.Module):
            def forward(self, x: "[31mf32[0m[34m[3, 2][0m[2m[34m[0m[2m[32m[0m", y: "[31mi64[0m[34m[][0m[2m[34m[0m[2m[32m[0m"):
                 [2m# File: /opt/conda/envs/py_3.8/lib/python3.8/site-packages/torch/_export/db/examples/assume_constant_result.py:16 in forward, code: return x[: self.get_item(y)][0m
                slice_1: "[31mf32[0m[34m[3, 2][0m[2m[34m[0m[2m[32m[0m" = torch.ops.aten.slice.Tensor(x, [34m0[0m, [34m0[0m, [34m4[0m);  [2mx = None[0m
                return (slice_1,)
                
    Graph signature: ExportGraphSignature(input_specs=[InputSpec(kind=<InputKind.USER_INPUT: 1>, arg=TensorArgument(name='x'), target=None, persistent=None), InputSpec(kind=<InputKind.USER_INPUT: 1>, arg=TensorArgument(name='y'), target=None, persistent=None)], output_specs=[OutputSpec(kind=<OutputKind.USER_OUTPUT: 1>, arg=TensorArgument(name='slice_1'), target=None)])
    Range constraints: {}
    


constrain_as_size_example
^^^^^^^^^^^^^^^^^^^^^^^^^

.. note::

    Tags: :doc:`torch.dynamic-value <torch.dynamic-value>`, :doc:`torch.escape-hatch <torch.escape-hatch>`

    Support Level: SUPPORTED

Original source code:

.. code-block:: python

    # mypy: allow-untyped-defs
    import torch
    
    
    class ConstrainAsSizeExample(torch.nn.Module):
        """
        If the value is not known at tracing time, you can provide hint so that we
        can trace further. Please look at torch._check and torch._check_is_size APIs.
        torch._check_is_size is used for values that NEED to be used for constructing
        tensor.
        """
    
        def forward(self, x):
            a = x.item()
            torch._check_is_size(a)
            torch._check(a <= 5)
            return torch.zeros((a, 5))
    
    
    example_args = (torch.tensor(4),)
    tags = {
        "torch.dynamic-value",
        "torch.escape-hatch",
    }
    model = ConstrainAsSizeExample()
    

    torch.export.export(model, example_args)

Result:

.. code-block::

    ExportedProgram:
        class GraphModule(torch.nn.Module):
            def forward(self, x: "[31mi64[0m[34m[][0m[2m[34m[0m[2m[32m[0m"):
                 [2m# File: /opt/conda/envs/py_3.8/lib/python3.8/site-packages/torch/_export/db/examples/constrain_as_size_example.py:14 in forward, code: a = x.item()[0m
                item: "Sym(u0)" = torch.ops.aten.item.default(x);  [2mx = None[0m
                
                 [2m# [0m
                sym_constrain_range_for_size_default = torch.ops.aten.sym_constrain_range_for_size.default(item)
                
                [2m# No stacktrace found for following nodes[0m
                sym_constrain_range = torch.ops.aten.sym_constrain_range.default(item, min = [34m0[0m, max = [34m5[0m)
                ge: "Sym(u0 >= 0)" = item >= [34m0[0m
                _assert_scalar = torch.ops.aten._assert_scalar.default(ge, [34m"Runtime assertion failed for expression 0 <= u0 on node 'ge'"[0m);  [2mge = None[0m
                le: "Sym(u0 <= 5)" = item <= [34m5[0m
                _assert_scalar_1 = torch.ops.aten._assert_scalar.default(le, [34m"Runtime assertion failed for expression u0 <= 5 on node 'le_1'"[0m);  [2mle = None[0m
                
                 [2m# File: /opt/conda/envs/py_3.8/lib/python3.8/site-packages/torch/_export/db/examples/constrain_as_size_example.py:17 in forward, code: return torch.zeros((a, 5))[0m
                zeros: "[31mf32[0m[34m[u0, 5][0m[2m[34m[0m[2m[32m[0m" = torch.ops.aten.zeros.default([34m[item, 5][0m, device = [34mdevice(type='cpu')[0m, pin_memory = [34mFalse[0m);  [2mitem = None[0m
                return (zeros,)
                
    Graph signature: ExportGraphSignature(input_specs=[InputSpec(kind=<InputKind.USER_INPUT: 1>, arg=TensorArgument(name='x'), target=None, persistent=None)], output_specs=[OutputSpec(kind=<OutputKind.USER_OUTPUT: 1>, arg=TensorArgument(name='zeros'), target=None)])
    Range constraints: {u0: VR[0, 5], u1: VR[0, 5], u2: VR[0, 5]}
    


constrain_as_value_example
^^^^^^^^^^^^^^^^^^^^^^^^^^

.. note::

    Tags: :doc:`torch.dynamic-value <torch.dynamic-value>`, :doc:`torch.escape-hatch <torch.escape-hatch>`

    Support Level: SUPPORTED

Original source code:

.. code-block:: python

    # mypy: allow-untyped-defs
    import torch
    
    
    class ConstrainAsValueExample(torch.nn.Module):
        """
        If the value is not known at tracing time, you can provide hint so that we
        can trace further. Please look at torch._check and torch._check_is_size APIs.
        torch._check is used for values that don't need to be used for constructing
        tensor.
        """
    
        def forward(self, x, y):
            a = x.item()
            torch._check(a >= 0)
            torch._check(a <= 5)
    
            if a < 6:
                return y.sin()
            return y.cos()
    
    
    example_args = (torch.tensor(4), torch.randn(5, 5))
    tags = {
        "torch.dynamic-value",
        "torch.escape-hatch",
    }
    model = ConstrainAsValueExample()
    

    torch.export.export(model, example_args)

Result:

.. code-block::

    ExportedProgram:
        class GraphModule(torch.nn.Module):
            def forward(self, x: "[31mi64[0m[34m[][0m[2m[34m[0m[2m[32m[0m", y: "[31mf32[0m[34m[5, 5][0m[2m[34m[0m[2m[32m[0m"):
                 [2m# File: /opt/conda/envs/py_3.8/lib/python3.8/site-packages/torch/_export/db/examples/constrain_as_value_example.py:14 in forward, code: a = x.item()[0m
                item: "Sym(u0)" = torch.ops.aten.item.default(x);  [2mx = None[0m
                
                [2m# No stacktrace found for following nodes[0m
                sym_constrain_range = torch.ops.aten.sym_constrain_range.default(item, min = [34m0[0m, max = [34m5[0m)
                ge: "Sym(u0 >= 0)" = item >= [34m0[0m
                _assert_scalar = torch.ops.aten._assert_scalar.default(ge, [34m"Runtime assertion failed for expression 0 <= u0 on node 'ge_1'"[0m);  [2mge = None[0m
                le: "Sym(u0 <= 5)" = item <= [34m5[0m;  [2mitem = None[0m
                _assert_scalar_1 = torch.ops.aten._assert_scalar.default(le, [34m"Runtime assertion failed for expression u0 <= 5 on node 'le_1'"[0m);  [2mle = None[0m
                
                 [2m# File: /opt/conda/envs/py_3.8/lib/python3.8/site-packages/torch/_export/db/examples/constrain_as_value_example.py:19 in forward, code: return y.sin()[0m
                sin: "[31mf32[0m[34m[5, 5][0m[2m[34m[0m[2m[32m[0m" = torch.ops.aten.sin.default(y);  [2my = None[0m
                return (sin,)
                
    Graph signature: ExportGraphSignature(input_specs=[InputSpec(kind=<InputKind.USER_INPUT: 1>, arg=TensorArgument(name='x'), target=None, persistent=None), InputSpec(kind=<InputKind.USER_INPUT: 1>, arg=TensorArgument(name='y'), target=None, persistent=None)], output_specs=[OutputSpec(kind=<OutputKind.USER_OUTPUT: 1>, arg=TensorArgument(name='sin'), target=None)])
    Range constraints: {u0: VR[0, 5], u1: VR[0, 5], u2: VR[0, 5]}
    
